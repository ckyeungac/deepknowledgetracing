{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import load_train_test\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# specify the gpu device\n",
    "# import os\n",
    "# from Tools.utils import _make_dir, load_options\n",
    "# options = load_options('options.json')\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"OCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "SPLIT_MSG=\"***********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "\n",
    "train_file = '0910_b_train.csv'\n",
    "test_file = '0910_b_test.csv'\n",
    "train_path= os.path.join(DATA_DIR, train_file)\n",
    "test_path = os.path.join(DATA_DIR, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/0910_b_train.csv\n",
      "10116 lines was read\n",
      "max_num_problems_answered: 1219\n",
      "num_problems: 124\n",
      "The number of students is 3134\n",
      "Finish reading data.\n",
      "Reading ./data/0910_b_test.csv\n",
      "2532 lines was read\n",
      "max_num_problems_answered: 1062\n",
      "num_problems: 124\n",
      "The number of students is 786\n",
      "Finish reading data.\n"
     ]
    }
   ],
   "source": [
    "students_train, students_test, max_num_steps, num_problems = load_train_test(train_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model\n",
    "\n",
    "### Placeholder Explanation\n",
    "X is the one-hot encoded input sequence of a student.\n",
    "y is the one-hot encoded correct sequence of a student.\n",
    "\n",
    "For example, the student i has a seq [1, 3, 1, 1, 2] with correct map [0, 1, 1, 1, 0]. The X_seq will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The X_corr map will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Then, it will be concatenated into $X^i$:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc|ccccc}\n",
    "        0&1&0&0&0&0&0&0&0&0\\\\\n",
    "        0&0&0&1&0&0&0&0&1&0\\\\\n",
    "        0&1&0&0&0&0&1&0&0&0\\\\\n",
    "        0&1&0&0&0&0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The last question '2' is not used in the $X^i$ because it is the last record that the student has and therefore used in $y$.\n",
    "So, $y$ would be seq [3, 1, 1, 2] with corr map [1, 1, 1, 0]\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_corr_to_onehot(seq, corr, num_steps, num_problems):\n",
    "    seq_oh = tf.one_hot(seq, depth=num_problems)\n",
    "    seq_oh_flat = tf.reshape(seq_oh, [-1, num_problems])\n",
    "    \n",
    "    # element-wise multiplication between Matrix and Vector\n",
    "    # the i-th column of Matrixelement-wisedly multiply the i-th element in the Vector\n",
    "    corr_flat = tf.reshape(corr, [-1])\n",
    "    corr_mat = tf.multiply(tf.transpose(seq_oh_flat), tf.cast(corr_flat, dtype=tf.float32))\n",
    "    corr_mat = tf.transpose(corr_mat)\n",
    "    corr_mat = tf.reshape(corr_mat, shape=[-1, num_steps, num_problems])\n",
    "    \n",
    "    concat = tf.concat([seq_oh, corr_mat], axis=2)\n",
    "    \n",
    "    return seq_oh, corr_mat, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network configuration\n",
    "batch_size = 64\n",
    "max_num_steps = max_num_steps - 1\n",
    "num_problems = num_problems\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "inputs_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "inputs_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "X_seq, X_corr, X = seq_corr_to_onehot(inputs_seq, inputs_corr, max_num_steps, num_problems)\n",
    "\n",
    "targets_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "targets_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "y_seq, y_corr, _ = seq_corr_to_onehot(targets_seq, targets_corr, max_num_steps, num_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1218), Dimension(248)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build up the network\n",
    "hl1_size = 200\n",
    "sequence_length = length(X_seq)\n",
    "\n",
    "with tf.variable_scope('hidden_layer_1'):\n",
    "    hl1_cell = tf.contrib.rnn.LSTMCell(num_units=hl1_size)\n",
    "    hl1_cell = tf.contrib.rnn.DropoutWrapper(hl1_cell, output_keep_prob=keep_prob)\n",
    "    hl1_output, hl1_state = tf.nn.dynamic_rnn(\n",
    "        hl1_cell,\n",
    "        X,\n",
    "        dtype=tf.float32,\n",
    "#         sequence_length=sequence_length\n",
    "    )\n",
    "\n",
    "last_layer_size = hl1_size\n",
    "last_layer_output, last_layer_state = hl1_output, hl1_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code block calculate the loss using tf.gather_nd\n",
    "W_yh = tf.Variable(tf.random_normal([last_layer_size, num_problems]), name=\"W_yh\")\n",
    "b_yh = tf.Variable(tf.constant(0.1, shape=[num_problems,]), name=\"b_yh\")\n",
    "\n",
    "last_layer_output_flat = tf.reshape(last_layer_output, [-1, last_layer_size])\n",
    "logits_flat = tf.matmul(last_layer_output_flat, W_yh) + b_yh\n",
    "preds_flat = tf.sigmoid(logits_flat)\n",
    "y_seq_flat = tf.cast(tf.reshape(y_seq, [-1, num_problems]), dtype=tf.float32)\n",
    "y_corr_flat = tf.cast(tf.reshape(y_corr, [-1, num_problems]), dtype=tf.float32)\n",
    "\n",
    "# get the indices where they are not equal to 0\n",
    "# the indices implies that a student has answered the question in the time step\n",
    "# and thereby exclude those time step that the student hasn't answered.\n",
    "target_indices = tf.where(tf.not_equal(y_seq_flat, 0))\n",
    "target_logits = tf.gather_nd(logits_flat, target_indices)\n",
    "target_preds = tf.gather_nd(preds_flat, target_indices)\n",
    "target_labels = tf.gather_nd(y_corr_flat, target_indices)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=target_logits, \n",
    "                                               labels=target_labels)\n",
    "total_loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(sess, print_loss=False):    \n",
    "    students = students_train\n",
    "    \n",
    "    best_test_auc = 0\n",
    "    best_epoch_idx = 0\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        \n",
    "        num_students = 10\n",
    "        num_students = len(students) \n",
    "\n",
    "        loss_train = 0\n",
    "        iteration = 1\n",
    "        \n",
    "        for batch_idx in range(0, num_students, batch_size):\n",
    "            start_idx = batch_idx\n",
    "            end_idx = min(num_students, batch_idx+batch_size)\n",
    "            \n",
    "            new_batch_size = end_idx - start_idx\n",
    "            \n",
    "            inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            \n",
    "            y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "            _optimizer, _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                    [optimizer, target_preds, target_labels, total_loss],\n",
    "                    feed_dict={\n",
    "                    inputs_seq: inputs_seq_batch,\n",
    "                    inputs_corr: inputs_corr_batch,\n",
    "                    targets_seq: y_seq_batch,\n",
    "                    targets_corr: y_corr_batch,\n",
    "                    keep_prob: 0.5,\n",
    "                })\n",
    "            \n",
    "            y_pred += [p for p in _target_preds]\n",
    "            y_true += [t for t in _target_labels]\n",
    "            loss_train = (iteration-1)/(iteration) * loss_train + _total_loss/iteration\n",
    "            iteration+=1\n",
    "        \n",
    "        # Print training information        \n",
    "        fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "        auc_train = auc(fpr, tpr)\n",
    "        print('Epoch {0:>4}, Train AUC: {1:.5}, Train Loss: {2:.5}'.format(epoch_idx+1, auc_train, loss_train))\n",
    "        \n",
    "        # evaluate on the test set\n",
    "        auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "        test_msg = \"Epoch {0:>4}, Test AUC: {1:.5}, Test Loss: {2:.5}\".format(epoch_idx+1, auc_test, loss_test)\n",
    "        if auc_test > best_test_auc:\n",
    "            test_msg += \"*\"\n",
    "            best_epoch_idx = epoch_idx\n",
    "            best_test_auc = auc_test\n",
    "            saver.save(sess=sess, save_path=save_path)\n",
    "        print(test_msg)\n",
    "        print(SPLIT_MSG)        \n",
    "        # quit the training if there is no improve in AUC for 20 epochs.\n",
    "        if epoch_idx - best_epoch_idx >= 20:\n",
    "            print(\"No improvement shown in 20 epochs. Quit Training.\")\n",
    "            break\n",
    "    \n",
    "    print(\"The best testing result occured at: {0}-th epoch, with testing AUC: {1:.5}\".format(best_epoch_idx, best_test_auc))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def evaluate(sess, is_train=False):    \n",
    "    if is_train:\n",
    "        students = students_train\n",
    "    else:\n",
    "        students = students_test\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    iteration = 1\n",
    "    _loss = 0\n",
    "    \n",
    "    num_students = 10\n",
    "    num_students = len(students)\n",
    "    \n",
    "    for batch_idx in range(0, num_students, batch_size):\n",
    "        start_idx = batch_idx\n",
    "        end_idx = min(num_students, batch_idx+batch_size)\n",
    "\n",
    "        new_batch_size = end_idx - start_idx\n",
    "\n",
    "        inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                [target_preds, target_labels, total_loss],\n",
    "                feed_dict={\n",
    "                inputs_seq: inputs_seq_batch,\n",
    "                inputs_corr: inputs_corr_batch,\n",
    "                targets_seq: y_seq_batch,\n",
    "                targets_corr: y_corr_batch,\n",
    "                keep_prob: 1,\n",
    "            })\n",
    "\n",
    "        y_pred += [p for p in _target_preds]\n",
    "        y_true += [t for t in _target_labels]\n",
    "        _loss = (iteration-1)/(iteration) * _loss + _total_loss/iteration\n",
    "        iteration+=1\n",
    "\n",
    "    fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return (auc_score, _loss)\n",
    "\n",
    "def get_student_output_layer(sess, student):\n",
    "    num_steps = len(student[1]) - 1\n",
    "    shape = (1, num_steps)\n",
    "    _inputs_seq = np.array(student[1][:-1]).reshape(shape)\n",
    "    _inputs_corr = np.array(student[2][:-1]).reshape(shape)\n",
    "    \n",
    "    _y_seq = np.array(student[1][1:]).reshape(shape)\n",
    "    _y_corr = np.array(student[2][1:]).reshape(shape)\n",
    "    \n",
    "    _preds_flat = sess.run(\n",
    "        preds_flat,\n",
    "        feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    )    \n",
    "    return _preds_flat\n",
    "\n",
    "def get_student_hidden_layer(sess, student, layer_num=1):\n",
    "    num_steps = len(student[1]) - 1\n",
    "    shape = (1, num_steps)\n",
    "    _inputs_seq = np.array(student[1][:-1]).reshape(shape)\n",
    "    _inputs_corr = np.array(student[2][:-1]).reshape(shape)\n",
    "    \n",
    "    _y_seq = np.array(student[1][1:]).reshape(shape)\n",
    "    _y_corr = np.array(student[2][1:]).reshape(shape)\n",
    "    \n",
    "    \n",
    "    feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    \n",
    "    result = None\n",
    "    if layer_num == 1:\n",
    "        result = sess.run(\n",
    "            hl1_output,\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    elif layer_num == 2:\n",
    "        result = sess.run(\n",
    "            hl2_output,\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    else:\n",
    "        print(\"layer is not available\")\n",
    "        return None\n",
    "    return result[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define the tf saver\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/original/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WITH_CONFIG = True\n",
    "num_epochs = 1000\n",
    "\n",
    "### Start Training\n",
    "start_time = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "        print(\"Pre-trained model found, loading the previous variables\")\n",
    "    except:\n",
    "        print(\"Pre-trained model not found, train from scratch now.\")\n",
    "    optimize(sess)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"program run for: {0}s\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the hidden layer output\n",
    "As the hidden layer size is large, the visualization is a bit convoluted to be understanded even if we visualize it.\n",
    "In order to better visualize the hidden layer result. A rough idea is to extract all the student hidden layer output, and then perform PCA over those vector. Afterwards, check the proportion of variance and its eigen value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved variable to the current session.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/original/model\n",
      "auc_test: 0.81873, loss_test: 0.81873\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"Loading the saved variable to the current session.\")\n",
    "saver.restore(sess=sess, save_path=save_path)\n",
    "\n",
    "auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "print (\"auc_test: {0:.5}, loss_test: {0:.5}\".format(auc_test, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hl1_outputs = []\n",
    "# for student in students_train:\n",
    "#     # student basic information\n",
    "#     num_question_answered = student[0]\n",
    "    \n",
    "#     # it is the hidden layer output sequence of the student. (in shape [max_num_steps, hl1_size])\n",
    "#     hl1 = get_student_hidden_layer(sess, student=student, layer_num=1)\n",
    "#     hl1 = hl1[:num_question_answered]\n",
    "    \n",
    "#     hl1_outputs += [hl1_output for hl1_output in hl1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(hl1_outputs)\n",
    "hl1_pca = pca.transform(hl1_outputs)\n",
    "pca_dim = len(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "hl1_pca.shape\n",
    "hl1_pca = np.transpose(hl1_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the pca\n",
    "import pickle\n",
    "with open('original_1hl_hl1_outputs.pkl', 'wb') as fid:\n",
    "    pickle.dump(hl1_outputs, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('original_1hl_hl1_outputs.pkl', 'rb') as fid:\n",
    "    hl1_outputs = pickle.load(fid)\n",
    "    \n",
    "len(hl1_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca.fit(hl1_outputs)\n",
    "hl1_pca = pca.transform(hl1_outputs)\n",
    "pca_dim = len(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "hl1_pca.shape\n",
    "hl1_pca = np.transpose(hl1_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "In the following, the student output and hidden layer will be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "print(\"Loading the saved variable to the current session.\")\n",
    "saver.restore(sess=sess, save_path=save_path)\n",
    "\n",
    "auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "print (\"auc_test: {0:.5}, loss_test: {0:.5}\".format(auc_test, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "#http://bokeh.pydata.org/en/0.10.0/docs/gallery/cat_heatmap_chart.html\n",
    "\n",
    "def plot_heatmap(data, x_labels, y_labels, second_x_labels=None, fig_size_inches=[15, 5], cmap=plt.cm.Blues):\n",
    "#     plt.figure(figsize=(40,100))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(data, cmap=cmap)\n",
    "    \n",
    "    # Format\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    # turn off the frame\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(x_labels)) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(len(y_labels)) + 0.5, minor=False)\n",
    "    \n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    # set the label\n",
    "    ax.set_xticklabels(x_labels, minor=False)\n",
    "    ax.set_yticklabels(y_labels, minor=False)\n",
    "    ax.set_xlabel(\"the skill id answered at the time step\")\n",
    "    ax.set_ylabel(\"the skill id of the output layer\")\n",
    "\n",
    "    fig.set_size_inches(fig_size_inches[0], fig_size_inches[1])\n",
    "    \n",
    "    # second axis label\n",
    "    if second_x_labels != None:\n",
    "        ax2 = ax.twiny()\n",
    "        ax2.set_xticks(np.arange(len(second_x_labels)) + 0.5, minor=False)\n",
    "        ax2.set_xticklabels(second_x_labels)\n",
    "        ax2.set_xlabel(\"Correct Label\")\n",
    "        ax2.xaxis.tick_top()\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    \n",
    "#     fig.colorbar(heatmap, fraction=0.02, pad=0.04)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 21, 38, 40, 71, 75, 81, 94, 98, 102, 106, 112, 115, 124, 147, 150, 154, 170, 180, 182, 187, 203, 205, 222, 224, 235, 243, 255, 276, 281, 285, 292, 294, 299, 311, 329, 335, 344, 345, 350, 367, 370, 371, 382, 393, 396, 409, 413, 431, 437, 443, 444, 460, 473, 485, 486, 491, 493, 497, 504, 506, 509, 511, 529, 531, 586, 593, 595, 599, 607, 615, 622, 626, 629, 631, 636, 645, 648, 651, 660, 661, 663, 685, 702, 722, 731, 733, 742, 757, 765, 767, 781]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "for i in range(len(students_test)):\n",
    "    student = students_test[i]\n",
    "    num_question_answered = student[0]\n",
    "    question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))\n",
    "    num_distict_question = len(question_ids_answered)\n",
    "    \n",
    "    if 50 >= num_question_answered >= 20 and 10 >= num_distict_question >= 5:\n",
    "        targets.append(i)\n",
    "    \n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting one student to visualize\n",
    "# bad example: 733\n",
    "# good example: 21\n",
    "sid = targets[1]\n",
    "student = students_test[sid]\n",
    "num_question_answered = student[0]\n",
    "question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['15', '74', '74', '107', '115', '107', '115', '107', '115', '107', '115', '107', '115', '107', '115', '107', '115', '107', '115', '107', '115', '107', '115', '43', '43', '43', '43', '43', '43', '43', '43', '43', '43', '115', '115', '115', '115', '115', '115']\n",
      "['1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '1', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "output_layer = get_student_output_layer(sess, student)\n",
    "\n",
    "output_layer = output_layer[:num_question_answered, question_ids_answered]\n",
    "output_layer = np.transpose(output_layer)\n",
    "\n",
    "question_seq = student[1][:num_question_answered]\n",
    "correct_seq = student[2][:num_question_answered]\n",
    "\n",
    "print(num_question_answered),\n",
    "print(question_seq)\n",
    "print(correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAAFaCAYAAACuSeQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsPmTJEmSpB74f/bMTc7k66jlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27c444c8a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(output_layer, x_labels=question_seq, y_labels=question_ids_answered, second_x_labels=correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl1 = get_student_hidden_layer(sess, student=student, layer_num=1)\n",
    "hl1 = hl1[:num_question_answered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl1_pca = pca.transform(hl1)\n",
    "hl1_output = np.transpose(hl1_pca)\n",
    "print(hl1_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_labels=[\"{}({})\".format(question_seq[i], correct_seq[i]) for i in range(num_question_answered)]\n",
    "print(x_labels)\n",
    "y_labels = range(hl1_output.shape[0])\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# red: negative, white: zero, blue: positive\n",
    "plot_heatmap(hl1_output, \n",
    "             x_labels=x_labels, \n",
    "             y_labels=y_labels,\n",
    "#              second_x_labels=correct_seq, \n",
    "             fig_size_inches=[15, 15],\n",
    "            cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
