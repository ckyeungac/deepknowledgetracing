{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# specify the gpu device\n",
    "# import os\n",
    "# from Tools.utils import _make_dir, load_options\n",
    "# options = load_options('options.json')\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"OCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "#train_file = os.path.join(DATA_DIR, 'builder_train.csv')\n",
    "#test_file = os.path.join(DATA_DIR, 'builder_test.csv')\n",
    "train_file = os.path.join(DATA_DIR, '0910_b_train.csv')\n",
    "test_file = os.path.join(DATA_DIR, '0910_b_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data_from_csv(filename):\n",
    "    rows = []\n",
    "    max_num_problems_answered = 0\n",
    "    num_problems = 0\n",
    "    \n",
    "    print(\"Reading {0}\".format(filename))\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            rows.append(row)\n",
    "    print(\"{0} lines was read\".format(len(rows)))\n",
    "    \n",
    "    # tuples stores the student answering sequence as \n",
    "    # ([num_problems_answered], [problem_ids], [is_corrects])\n",
    "    tuples = []\n",
    "    for i in range(0, len(rows), 3):\n",
    "        # numbers of problem a student answered\n",
    "        num_problems_answered = int(rows[i][0])\n",
    "        \n",
    "        # only keep student with at least 3 records.\n",
    "        if num_problems_answered < 3:\n",
    "            continue\n",
    "        \n",
    "        problem_ids = rows[i+1]\n",
    "        is_corrects = rows[i+2]\n",
    "        \n",
    "        invalid_ids_loc = [i for i, pid in enumerate(problem_ids) if pid=='']        \n",
    "        for invalid_loc in invalid_ids_loc:\n",
    "            del problem_ids[invalid_loc]\n",
    "            del is_corrects[invalid_loc]\n",
    "        \n",
    "        tup =(num_problems_answered, problem_ids, is_corrects)\n",
    "        tuples.append(tup)\n",
    "        \n",
    "        if max_num_problems_answered < num_problems_answered:\n",
    "            max_num_problems_answered = num_problems_answered\n",
    "        \n",
    "        pid = max(int(pid) for pid in problem_ids if pid!='')\n",
    "        if num_problems < pid:\n",
    "            num_problems = pid\n",
    "    # add 1 to num_problems because 0 is in the pid\n",
    "    num_problems+=1\n",
    "\n",
    "    #shuffle the tuple\n",
    "    random.shuffle(tuples)\n",
    "\n",
    "    print (\"max_num_problems_answered:\", max_num_problems_answered)\n",
    "    print (\"num_problems:\", num_problems)\n",
    "    print(\"The number of students is {0}\".format(len(tuples)))\n",
    "    print(\"Finish reading data.\")\n",
    "    \n",
    "    return tuples, max_num_problems_answered, num_problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def padding(student_tuple, target_length):\n",
    "    num_problems_answered = student_tuple[0]\n",
    "    question_seq = student_tuple[1]\n",
    "    question_corr = student_tuple[2]\n",
    "    \n",
    "    pad_length = target_length - num_problems_answered\n",
    "    question_seq += [-1]*pad_length\n",
    "    question_corr += [0]*pad_length\n",
    "    \n",
    "    new_student_tuple = (num_problems_answered, question_seq, question_corr)\n",
    "    return new_student_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/0910_b_train.csv\n",
      "10116 lines was read\n",
      "max_num_problems_answered: 1219\n",
      "num_problems: 124\n",
      "The number of students is 3134\n",
      "Finish reading data.\n",
      "Reading ./data/0910_b_test.csv\n",
      "2532 lines was read\n",
      "max_num_problems_answered: 1062\n",
      "num_problems: 124\n",
      "The number of students is 786\n",
      "Finish reading data.\n"
     ]
    }
   ],
   "source": [
    "students_train, max_num_problems_answered_train, num_problems_train = \\\n",
    "read_data_from_csv(train_file)\n",
    "\n",
    "students_train = [padding(student_tuple, max_num_problems_answered_train) \n",
    "                  for student_tuple in students_train]\n",
    "\n",
    "students_test, max_num_problems_answered_test, num_problems_test = \\\n",
    "read_data_from_csv(test_file)\n",
    "\n",
    "students_test = [padding(student_tuple, max_num_problems_answered_train) \n",
    "                  for student_tuple in students_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model\n",
    "\n",
    "### Placeholder Explanation\n",
    "X is the one-hot encoded input sequence of a student.\n",
    "y is the one-hot encoded correct sequence of a student.\n",
    "\n",
    "For example, the student i has a seq [1, 3, 1, 2, 2] with correct map [0, 1, 1, 0, 0]. The X_seq will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&1&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The X_corr map will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Our desire $X^i$ will be encoded as the following:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&-1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&-1&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "The last question '2' is not used in the $X^i$ because it is the last record that the student has and therefore used in $y$.\n",
    "So, $y$ would be seq [3, 1, 2, 2] with corr map [1, 1, 0, 0]\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_corr_to_onehot(seq, corr, num_steps, num_problems):\n",
    "    seq_oh = tf.one_hot(seq, depth=num_problems)\n",
    "    seq_oh_flat = tf.reshape(seq_oh, [-1, num_problems])\n",
    "    \n",
    "    # element-wise multiplication between Matrix and Vector\n",
    "    # the i-th column of Matrixelement-wisedly multiply the i-th element in the Vector\n",
    "    corr_flat = tf.reshape(corr, [-1])\n",
    "    corr_mat = tf.multiply(tf.transpose(seq_oh_flat), tf.cast(corr_flat, dtype=tf.float32))\n",
    "    corr_mat = tf.transpose(corr_mat)\n",
    "    corr_mat = tf.reshape(corr_mat, shape=[-1, num_steps, num_problems])\n",
    "    \n",
    "    corr_mat_value_two = corr_mat * 2\n",
    "    \n",
    "    X = corr_mat_value_two - seq_oh\n",
    "    \n",
    "    return seq_oh, corr_mat, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network configuration\n",
    "batch_size = 32\n",
    "num_layers = 2\n",
    "state_size = 200\n",
    "num_steps = max_num_problems_answered_train-1\n",
    "num_problems = num_problems_train\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "inputs_seq = tf.placeholder(tf.int32, [None, num_steps])\n",
    "inputs_corr = tf.placeholder(tf.int32, [None, num_steps])\n",
    "X_seq, X_corr, X = seq_corr_to_onehot(inputs_seq, inputs_corr, num_steps, num_problems)\n",
    "\n",
    "targets_seq = tf.placeholder(tf.int32, [None, num_steps])\n",
    "targets_corr = tf.placeholder(tf.int32, [None, num_steps])\n",
    "y_seq, y_corr, _ = seq_corr_to_onehot(targets_seq, targets_corr, num_steps, num_problems)\n",
    "\n",
    "init_state = tf.placeholder(tf.float32, [num_layers, 2, None, state_size])\n",
    "state_per_layer_list  = tf.unstack(init_state, axis=0)\n",
    "rnn_tuple_state = tuple([tf.contrib.rnn.LSTMStateTuple(\n",
    "            state_per_layer_list[idx][0],\n",
    "            state_per_layer_list[idx][1]\n",
    "        ) for idx in range(num_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sub:0' shape=(?, 1218, 124) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Configuration\n",
    "There are basically 2 elements needed to construct the LSTM network\n",
    "1. The cell, and\n",
    "2. The rnn structure.\n",
    "\n",
    "The cell is defined via the tf.contrib.rnn library. It supports the multilayer RNN as well. \n",
    "\n",
    "The RNN is defined via the tf.nn.dynamic_rnn. It is parameterized by the cell defined, the input X, and a initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the states series is:\n",
      " Tensor(\"rnn/rnn/transpose:0\", shape=(?, 1218, 200), dtype=float32)\n",
      "\n",
      "the current_state is:\n",
      " (LSTMStateTuple(c=<tf.Tensor 'rnn/rnn/while/Exit_2:0' shape=(?, 200) dtype=float32>, h=<tf.Tensor 'rnn/rnn/while/Exit_3:0' shape=(?, 200) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/rnn/while/Exit_4:0' shape=(?, 200) dtype=float32>, h=<tf.Tensor 'rnn/rnn/while/Exit_5:0' shape=(?, 200) dtype=float32>))\n"
     ]
    }
   ],
   "source": [
    "# build up the network\n",
    "with tf.variable_scope('cell'):\n",
    "    cells = []\n",
    "    for _ in range(num_layers):\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_units=state_size,\n",
    "                                       forget_bias=1.0,\n",
    "                                       state_is_tuple=True)\n",
    "\n",
    "        cell = tf.contrib.rnn.DropoutWrapper(cell,\n",
    "                                            output_keep_prob=keep_prob)\n",
    "        \n",
    "        cells.append(cell)\n",
    "    \n",
    "    cells = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=True)\n",
    "\n",
    "with tf.variable_scope('rnn'):\n",
    "    states_series, current_state = tf.nn.dynamic_rnn(cells, \n",
    "                                                    X,\n",
    "                                                    initial_state=rnn_tuple_state,\n",
    "                                                    time_major=False)\n",
    "\n",
    "print(\"the states series is:\\n\", states_series)\n",
    "print(\"\\nthe current_state is:\\n\", current_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this code block calculate the loss using tf.gather_nd\n",
    "W_yh = tf.Variable(tf.random_normal([state_size, num_problems]), name=\"W_yh\")\n",
    "b_yh = tf.Variable(tf.constant(0.1, shape=[num_problems,]), name=\"b_yh\")\n",
    "\n",
    "states_series = tf.reshape(states_series, [-1, state_size])\n",
    "logits_flat = tf.matmul(states_series, W_yh) + b_yh\n",
    "y_seq_flat = tf.cast(tf.reshape(y_seq, [-1, num_problems]), dtype=tf.float32)\n",
    "y_corr_flat = tf.cast(tf.reshape(y_corr, [-1, num_problems]), dtype=tf.float32)\n",
    "\n",
    "# get the indices where they are not equal to 0\n",
    "# the indices implies that a student has answered the question in the time step\n",
    "# and thereby exclude those time step that the student hasn't answered.\n",
    "target_indices = tf.where(tf.not_equal(y_seq_flat, 0))\n",
    "target_logits = tf.gather_nd(logits_flat, target_indices)\n",
    "target_labels = tf.gather_nd(y_corr_flat, target_indices)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=target_logits, \n",
    "                                               labels=target_labels)\n",
    "total_loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(sess):\n",
    "    students = students_train\n",
    "    \n",
    "    # update the network configuration\n",
    "    global num_steps\n",
    "    num_steps = max_num_problems_answered_train - 1\n",
    "    \n",
    "    for epoch_idx in range(num_epochs):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        num_students = len(students[:10])\n",
    "        iteration = 0\n",
    "        for batch_idx in range(0, num_students, batch_size):\n",
    "            start_idx = batch_idx\n",
    "            end_idx = min(num_students, batch_idx+batch_size)\n",
    "            \n",
    "            new_batch_size = end_idx - start_idx\n",
    "            _current_state = np.zeros((num_layers, 2, new_batch_size, state_size))\n",
    "            \n",
    "            inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            \n",
    "            y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "            _optimizer, _current_state, = sess.run(\n",
    "                    [optimizer, current_state],\n",
    "                    feed_dict={\n",
    "                    inputs_seq: inputs_seq_batch,\n",
    "                    inputs_corr: inputs_corr_batch,\n",
    "                    targets_seq: y_seq_batch,\n",
    "                    targets_corr: y_corr_batch,\n",
    "                    init_state: _current_state,\n",
    "                    keep_prob: 0.5,\n",
    "                })\n",
    "            \n",
    "            if iteration%10 == 0:\n",
    "                _total_loss= sess.run(total_loss,\n",
    "                    feed_dict={\n",
    "                    inputs_seq: inputs_seq_batch,\n",
    "                    inputs_corr: inputs_corr_batch,\n",
    "                    targets_seq: y_seq_batch,\n",
    "                    targets_corr: y_corr_batch,\n",
    "                    init_state: _current_state,\n",
    "                    keep_prob: 1,\n",
    "                })\n",
    "                print(\"Epoch {0:>4}, iteration {1:>4}, batch loss value: {2:.5}\".format(epoch_idx, iteration, _total_loss))\n",
    "            \n",
    "            iteration+=1\n",
    "        auc_train = evaluate(sess, is_train=True)\n",
    "        auc_test = evaluate(sess, is_train=False)\n",
    "        print(\"Epoch {0:>4}, Training AUC: {1:.5}, Testing AUC: {2:.5}\".format(epoch_idx, auc_train, auc_test))\n",
    "        \n",
    "\n",
    "def evaluate(sess, is_train=False):\n",
    "    global num_steps\n",
    "    \n",
    "    if is_train:\n",
    "        students = students_train\n",
    "        num_steps = max_num_problems_answered_train\n",
    "    else:\n",
    "        students = students_test\n",
    "        num_steps = max_num_problems_answered_test\n",
    "\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    num_students = len(students[:10])\n",
    "    for batch_idx in range(0, num_students, batch_size):\n",
    "        start_idx = batch_idx\n",
    "        end_idx = min(num_students, batch_idx+batch_size)\n",
    "\n",
    "        new_batch_size = end_idx - start_idx\n",
    "        _current_state = np.zeros((num_layers, 2, new_batch_size, state_size))\n",
    "\n",
    "        inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        _target_logits, _target_labels = sess.run(\n",
    "                [target_logits, target_labels],\n",
    "                feed_dict={\n",
    "                inputs_seq: inputs_seq_batch,\n",
    "                inputs_corr: inputs_corr_batch,\n",
    "                targets_seq: y_seq_batch,\n",
    "                targets_corr: y_corr_batch,\n",
    "                init_state: _current_state,\n",
    "                keep_prob: 1,\n",
    "            })\n",
    "\n",
    "        y_pred += [p for p in _target_logits]\n",
    "        y_true += [t for t in _target_labels]\n",
    "\n",
    "    fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WITH_CONFIG = True\n",
    "num_epochs = 25\n",
    "\n",
    "start_time = time.time()\n",
    "logger.info(\"Start the program...\")\n",
    "if WITH_CONFIG:\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        optimize(sess)\n",
    "else:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        optimize(sess)\n",
    "           \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"program run for: {0}s\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
