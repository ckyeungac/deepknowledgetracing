{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import load_train_test\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# specify the gpu device\n",
    "# import os\n",
    "# from Tools.utils import _make_dir, load_options\n",
    "# options = load_options('options.json')\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"OCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "SPLIT_MSG=\"***********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "train_file = '0910_b_train.csv'\n",
    "test_file = '0910_b_test.csv'\n",
    "train_path= os.path.join(DATA_DIR, train_file)\n",
    "test_path = os.path.join(DATA_DIR, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/0910_b_train.csv\n",
      "10116 lines was read\n",
      "max_num_problems_answered: 1219\n",
      "num_problems: 124\n",
      "The number of students is 3134\n",
      "Finish reading data.\n",
      "Reading ./data/0910_b_test.csv\n",
      "2532 lines was read\n",
      "max_num_problems_answered: 1062\n",
      "num_problems: 124\n",
      "The number of students is 786\n",
      "Finish reading data.\n"
     ]
    }
   ],
   "source": [
    "students_train, students_test, max_num_steps, num_problems = load_train_test(train_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model\n",
    "\n",
    "### Placeholder Explanation\n",
    "X is the one-hot encoded input sequence of a student.\n",
    "y is the one-hot encoded correct sequence of a student.\n",
    "\n",
    "For example, the student i has a seq [1, 3, 1, 2, 2] with correct map [0, 1, 1, 0, 0]. The X_seq will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&1&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The X_corr map will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Our desire $X^i$ will be encoded as the following:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&-1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "The last question '2' is not used in the $X^i$ because it is the last record that the student has and therefore used in $y$.\n",
    "So, $y$ would be seq [3, 1, 2, 2] with corr map [1, 1, 0, 0]\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_corr_to_onehot(seq, corr, num_steps, num_problems):\n",
    "    seq_oh = tf.one_hot(seq, depth=num_problems)\n",
    "    seq_oh_flat = tf.reshape(seq_oh, [-1, num_problems])\n",
    "    \n",
    "    # element-wise multiplication between Matrix and Vector\n",
    "    # the i-th column of Matrixelement-wisedly multiply the i-th element in the Vector\n",
    "    corr_flat = tf.reshape(corr, [-1])\n",
    "    corr_mat = tf.multiply(tf.transpose(seq_oh_flat), tf.cast(corr_flat, dtype=tf.float32))\n",
    "    corr_mat = tf.transpose(corr_mat)\n",
    "    corr_mat = tf.reshape(corr_mat, shape=[-1, num_steps, num_problems])\n",
    "    \n",
    "    corr_mat_value_two = corr_mat * 2\n",
    "    \n",
    "    X = corr_mat_value_two - seq_oh\n",
    "    \n",
    "    return seq_oh, corr_mat, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network configuration\n",
    "batch_size = 32\n",
    "max_num_steps = max_num_steps - 1\n",
    "num_problems = num_problems\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "inputs_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "inputs_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "X_seq, X_corr, X = seq_corr_to_onehot(inputs_seq, inputs_corr, max_num_steps, num_problems)\n",
    "\n",
    "targets_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "targets_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "y_seq, y_corr, _ = seq_corr_to_onehot(targets_seq, targets_corr, max_num_steps, num_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1218), Dimension(124)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build up the network\n",
    "hl1_size = 200\n",
    "sequence_length = length(X_seq)\n",
    "\n",
    "with tf.variable_scope('hidden_layer_1'):\n",
    "    hl1_cell = tf.contrib.rnn.LSTMCell(num_units=hl1_size)\n",
    "    hl1_cell = tf.contrib.rnn.DropoutWrapper(hl1_cell, output_keep_prob=keep_prob)\n",
    "    hl1_output, hl1_state = tf.nn.dynamic_rnn(\n",
    "        hl1_cell,\n",
    "        X,\n",
    "        dtype=tf.float32,\n",
    "#         sequence_length=sequence_length\n",
    "    )\n",
    "\n",
    "last_layer_size = hl1_size\n",
    "last_layer_output, last_layer_state = hl1_output, hl1_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code block calculate the loss using tf.gather_nd\n",
    "W_yh = tf.Variable(tf.random_normal([last_layer_size, num_problems]), name=\"W_yh\")\n",
    "b_yh = tf.Variable(tf.constant(0.1, shape=[num_problems,]), name=\"b_yh\")\n",
    "\n",
    "last_layer_output_flat = tf.reshape(last_layer_output, [-1, last_layer_size])\n",
    "logits_flat = tf.matmul(last_layer_output_flat, W_yh) + b_yh\n",
    "preds_flat = tf.sigmoid(logits_flat)\n",
    "y_seq_flat = tf.cast(tf.reshape(y_seq, [-1, num_problems]), dtype=tf.float32)\n",
    "y_corr_flat = tf.cast(tf.reshape(y_corr, [-1, num_problems]), dtype=tf.float32)\n",
    "\n",
    "# get the indices where they are not equal to 0\n",
    "# the indices implies that a student has answered the question in the time step\n",
    "# and thereby exclude those time step that the student hasn't answered.\n",
    "target_indices = tf.where(tf.not_equal(y_seq_flat, 0))\n",
    "target_logits = tf.gather_nd(logits_flat, target_indices)\n",
    "target_preds = tf.gather_nd(preds_flat, target_indices)\n",
    "target_labels = tf.gather_nd(y_corr_flat, target_indices)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=target_logits, \n",
    "                                               labels=target_labels)\n",
    "total_loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(sess, print_loss=False):    \n",
    "    students = students_train\n",
    "    \n",
    "    best_test_auc = 0\n",
    "    best_epoch_idx = 0\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        \n",
    "        num_students = 10\n",
    "        num_students = len(students) \n",
    "\n",
    "        loss_train = 0\n",
    "        iteration = 1\n",
    "        \n",
    "        for batch_idx in range(0, num_students, batch_size):\n",
    "            start_idx = batch_idx\n",
    "            end_idx = min(num_students, batch_idx+batch_size)\n",
    "            \n",
    "            new_batch_size = end_idx - start_idx\n",
    "            \n",
    "            inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            \n",
    "            y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "            _optimizer, _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                    [optimizer, target_preds, target_labels, total_loss],\n",
    "                    feed_dict={\n",
    "                    inputs_seq: inputs_seq_batch,\n",
    "                    inputs_corr: inputs_corr_batch,\n",
    "                    targets_seq: y_seq_batch,\n",
    "                    targets_corr: y_corr_batch,\n",
    "                    keep_prob: 0.5,\n",
    "                })\n",
    "            \n",
    "            y_pred += [p for p in _target_preds]\n",
    "            y_true += [t for t in _target_labels]\n",
    "            loss_train = (iteration-1)/(iteration) * loss_train + _total_loss/iteration\n",
    "            iteration+=1\n",
    "        \n",
    "        # Print training information        \n",
    "        fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "        auc_train = auc(fpr, tpr)\n",
    "        print('Epoch {0:>4}, Train AUC: {1:.5}, Train Loss: {2:.5}'.format(epoch_idx+1, auc_train, loss_train))\n",
    "        \n",
    "        # evaluate on the test set\n",
    "        auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "        test_msg = \"Epoch {0:>4}, Test AUC: {1:.5}, Test Loss: {2:.5}\".format(epoch_idx+1, auc_test, loss_test)\n",
    "        if auc_test > best_test_auc:\n",
    "            test_msg += \"*\"\n",
    "            best_epoch_idx = epoch_idx\n",
    "            best_test_auc = auc_test\n",
    "            saver.save(sess=sess, save_path=save_path)\n",
    "        print(test_msg)\n",
    "        print(SPLIT_MSG)        \n",
    "        # quit the training if there is no improve in AUC for 20 epochs.\n",
    "        if epoch_idx - best_epoch_idx >= 20:\n",
    "            print(\"No improvement shown in 20 epochs. Quit Training.\")\n",
    "            break\n",
    "    print(\"The best testing result occured at: {0}-th epoch, with testing AUC: {1:.5}\".format(best_epoch_idx, best_test_auc))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def evaluate(sess, is_train=False):    \n",
    "    if is_train:\n",
    "        students = students_train\n",
    "    else:\n",
    "        students = students_test\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    iteration = 1\n",
    "    _loss = 0\n",
    "    \n",
    "    num_students = 10\n",
    "    num_students = len(students)\n",
    "    \n",
    "    for batch_idx in range(0, num_students, batch_size):\n",
    "        start_idx = batch_idx\n",
    "        end_idx = min(num_students, batch_idx+batch_size)\n",
    "\n",
    "        new_batch_size = end_idx - start_idx\n",
    "\n",
    "        inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                [target_preds, target_labels, total_loss],\n",
    "                feed_dict={\n",
    "                inputs_seq: inputs_seq_batch,\n",
    "                inputs_corr: inputs_corr_batch,\n",
    "                targets_seq: y_seq_batch,\n",
    "                targets_corr: y_corr_batch,\n",
    "                keep_prob: 1,\n",
    "            })\n",
    "\n",
    "        y_pred += [p for p in _target_preds]\n",
    "        y_true += [t for t in _target_labels]\n",
    "        _loss = (iteration-1)/(iteration) * _loss + _total_loss/iteration\n",
    "        iteration+=1\n",
    "\n",
    "    fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return (auc_score, _loss)\n",
    "\n",
    "def get_student_output_layer(sess, student):\n",
    "    num_steps = len(student[1]) - 1\n",
    "    shape = (1, num_steps)\n",
    "    _inputs_seq = np.array(student[1][:-1]).reshape(shape)\n",
    "    _inputs_corr = np.array(student[2][:-1]).reshape(shape)\n",
    "    \n",
    "    _y_seq = np.array(student[1][1:]).reshape(shape)\n",
    "    _y_corr = np.array(student[2][1:]).reshape(shape)\n",
    "    \n",
    "    _preds_flat = sess.run(\n",
    "        preds_flat,\n",
    "        feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    )    \n",
    "    return _preds_flat\n",
    "\n",
    "def get_student_hidden_layer(sess, student, layer_num=1):\n",
    "    _inputs_seq = np.array(tup[1][:-1])\n",
    "    _inputs_corr = np.array(tup[2][:-1])\n",
    "    \n",
    "    _y_seq = np.array(tup[1][1:])\n",
    "    _y_corr = np.array(tup[2][1:])\n",
    "    \n",
    "    feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    \n",
    "    result = None\n",
    "    if layer_num == 1:\n",
    "        result = sess.run(\n",
    "            [hl1_output],\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    elif layer_num == 2:\n",
    "        result = sess.run(\n",
    "            [hl2_output],\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    else:\n",
    "        print(\"layer is not available\")\n",
    "        return None\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define the tf saver\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/v2_1hl_200'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WITH_CONFIG = True\n",
    "num_epochs = 1000\n",
    "\n",
    "### Start Training\n",
    "start_time = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "        print(\"Pre-trained model found, loading the previous variables\")\n",
    "    except:\n",
    "        print(\"Pre-trained model not found, train from scratch now.\")\n",
    "    optimize(sess)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"program run for: {0}s\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "In the following, the student output and hidden layer will be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved variable to the current session.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/v2_1hl_200\\model\n",
      "auc_test: 0.81796, loss_test: 0.81796\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"Loading the saved variable to the current session.\")\n",
    "saver.restore(sess=sess, save_path=save_path)\n",
    "\n",
    "auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "print (\"auc_test: {0:.5}, loss_test: {0:.5}\".format(auc_test, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer_1/rnn/lstm_cell/kernel:0' shape=(324, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer_1/rnn/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'W_yh:0' shape=(200, 124) dtype=float32_ref>,\n",
       " <tf.Variable 'b_yh:0' shape=(124,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "#http://bokeh.pydata.org/en/0.10.0/docs/gallery/cat_heatmap_chart.html\n",
    "\n",
    "def plot_heatmap(data, x_labels, y_labels, second_x_labels=None, fig_size_inches=[15, 5]):\n",
    "#     plt.figure(figsize=(40,100))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(data, cmap=plt.cm.Blues)\n",
    "    \n",
    "    # Format\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    # turn off the frame\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(x_labels)) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(len(y_labels)) + 0.5, minor=False)\n",
    "    \n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    # set the label\n",
    "    ax.set_xticklabels(x_labels, minor=False)\n",
    "    ax.set_yticklabels(y_labels, minor=False)\n",
    "    ax.set_xlabel(\"the skill id answered at the time step\")\n",
    "    ax.set_ylabel(\"the skill id of the output layer\")\n",
    "\n",
    "    fig.set_size_inches(fig_size_inches[0], fig_size_inches[1])\n",
    "    \n",
    "    # second axis label\n",
    "    if second_x_labels != None:\n",
    "        ax2 = ax.twiny()\n",
    "        ax2.set_xticks(np.arange(len(second_x_labels)) + 0.5, minor=False)\n",
    "        ax2.set_xticklabels(second_x_labels)\n",
    "        ax2.set_xlabel(\"Correct Label\")\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 21, 38, 40, 71, 75, 81, 94, 98, 102, 106, 112, 115, 124, 147, 150, 154, 170, 180, 182, 187, 203, 205, 222, 224, 235, 243, 255, 276, 281, 285, 292, 294, 299, 311, 329, 335, 344, 345, 350, 367, 370, 371, 382, 393, 396, 409, 413, 431, 437, 443, 444, 460, 473, 485, 486, 491, 493, 497, 504, 506, 509, 511, 529, 531, 586, 593, 595, 599, 607, 615, 622, 626, 629, 631, 636, 645, 648, 651, 660, 661, 663, 685, 702, 722, 731, 733, 742, 757, 765, 767, 781]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "for i in range(len(students_test)):\n",
    "    student = students_test[i]\n",
    "    num_question_answered = student[0]\n",
    "    question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))\n",
    "    num_distict_question = len(question_ids_answered)\n",
    "    \n",
    "    if 50 >= num_question_answered >= 20 and 10 >= num_distict_question >= 5:\n",
    "        targets.append(i)\n",
    "    \n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting one student to visualize\n",
    "# bad example: 733()\n",
    "# good example: 38(2)\n",
    "\n",
    "sid = targets[-6]\n",
    "student = students_test[sid]\n",
    "num_question_answered = student[0]\n",
    "question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "['37', '37', '41', '36', '41', '36', '37', '37', '72', '37', '72', '37', '41', '36', '41', '36', '41', '36', '41', '36', '41', '36', '41', '36', '41', '36', '36', '36', '37', '37', '41', '36', '70']\n",
      "['1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "output_layer = get_student_output_layer(sess, student)\n",
    "\n",
    "output_layer = output_layer[:num_question_answered, question_ids_answered]\n",
    "output_layer = np.transpose(output_layer)\n",
    "\n",
    "question_seq = student[1][:num_question_answered]\n",
    "correct_seq = student[2][:num_question_answered]\n",
    "\n",
    "print(num_question_answered),\n",
    "print(question_seq)\n",
    "print(correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFaCAYAAABMlf9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYYEnSZIkSR1hgSdJkiRJHfF/ASrIp3pmgb7IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22a6042a978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(output_layer, x_labels=question_seq, y_labels=question_ids_answered, second_x_labels=correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
