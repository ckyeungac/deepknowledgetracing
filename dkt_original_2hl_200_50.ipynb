{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import load_train_test\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# specify the gpu device\n",
    "# import os\n",
    "# from Tools.utils import _make_dir, load_options\n",
    "# options = load_options('options.json')\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"OCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "SPLIT_MSG=\"***********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "train_file = '0910_b_train.csv'\n",
    "test_file = '0910_b_test.csv'\n",
    "train_path= os.path.join(DATA_DIR, train_file)\n",
    "test_path = os.path.join(DATA_DIR, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/0910_b_train.csv\n",
      "10116 lines was read\n",
      "max_num_problems_answered: 1219\n",
      "num_problems: 124\n",
      "The number of students is 3134\n",
      "Finish reading data.\n",
      "Reading ./data/0910_b_test.csv\n",
      "2532 lines was read\n",
      "max_num_problems_answered: 1062\n",
      "num_problems: 124\n",
      "The number of students is 786\n",
      "Finish reading data.\n"
     ]
    }
   ],
   "source": [
    "students_train, students_test, max_num_steps, num_problems = load_train_test(train_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model\n",
    "\n",
    "### Placeholder Explanation\n",
    "X is the one-hot encoded input sequence of a student.\n",
    "y is the one-hot encoded correct sequence of a student.\n",
    "\n",
    "For example, the student i has a seq [1, 3, 1, 2, 2] with correct map [0, 1, 1, 0, 0]. The X_seq will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&1&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The X_corr map will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Our desire $X^i$ will be encoded as the following:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&-1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "The last question '2' is not used in the $X^i$ because it is the last record that the student has and therefore used in $y$.\n",
    "So, $y$ would be seq [3, 1, 2, 2] with corr map [1, 1, 0, 0]\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_corr_to_onehot(seq, corr, num_steps, num_problems):\n",
    "    seq_oh = tf.one_hot(seq, depth=num_problems)\n",
    "    seq_oh_flat = tf.reshape(seq_oh, [-1, num_problems])\n",
    "    \n",
    "    # element-wise multiplication between Matrix and Vector\n",
    "    # the i-th column of Matrixelement-wisedly multiply the i-th element in the Vector\n",
    "    corr_flat = tf.reshape(corr, [-1])\n",
    "    corr_mat = tf.multiply(tf.transpose(seq_oh_flat), tf.cast(corr_flat, dtype=tf.float32))\n",
    "    corr_mat = tf.transpose(corr_mat)\n",
    "    corr_mat = tf.reshape(corr_mat, shape=[-1, num_steps, num_problems])\n",
    "    \n",
    "    concat = tf.concat([seq_oh, corr_mat], axis=2)\n",
    "    \n",
    "    return seq_oh, corr_mat, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network configuration\n",
    "batch_size = 32\n",
    "max_num_steps = max_num_steps - 1\n",
    "num_problems = num_problems\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "inputs_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "inputs_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "X_seq, X_corr, X = seq_corr_to_onehot(inputs_seq, inputs_corr, max_num_steps, num_problems)\n",
    "\n",
    "targets_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "targets_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "y_seq, y_corr, _ = seq_corr_to_onehot(targets_seq, targets_corr, max_num_steps, num_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1218), Dimension(248)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hidden layer 2 states series is:\n",
      " Tensor(\"hidden_layer_2/rnn/transpose:0\", shape=(?, 1218, 50), dtype=float32)\n",
      "\n",
      "the current_state is:\n",
      " LSTMStateTuple(c=<tf.Tensor 'hidden_layer_2/rnn/while/Exit_2:0' shape=(?, 50) dtype=float32>, h=<tf.Tensor 'hidden_layer_2/rnn/while/Exit_3:0' shape=(?, 50) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "# build up the network\n",
    "hl1_size = 200\n",
    "hl2_size = 50\n",
    "sequence_length = length(X_seq)\n",
    "\n",
    "with tf.variable_scope('hidden_layer_1'):\n",
    "    hl1_cell = tf.contrib.rnn.LSTMCell(num_units=hl1_size)\n",
    "    hl1_cell = tf.contrib.rnn.DropoutWrapper(hl1_cell, output_keep_prob=keep_prob)\n",
    "    hl1_output, hl1_state = tf.nn.dynamic_rnn(\n",
    "        hl1_cell,\n",
    "        X,\n",
    "        dtype=tf.float32,\n",
    "        sequence_length=sequence_length\n",
    "    )\n",
    "\n",
    "with tf.variable_scope('hidden_layer_2'):\n",
    "    hl2_cell = tf.contrib.rnn.LSTMCell(num_units=hl2_size)\n",
    "    hl2_cell = tf.contrib.rnn.DropoutWrapper(hl2_cell, output_keep_prob=keep_prob)\n",
    "    hl2_output, hl2_state = tf.nn.dynamic_rnn(\n",
    "        hl2_cell,\n",
    "        hl1_output,\n",
    "        dtype=tf.float32,\n",
    "        sequence_length=sequence_length\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"the hidden layer 2 states series is:\\n\", hl2_output)\n",
    "print(\"\\nthe current_state is:\\n\", hl2_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cost(output, target):\n",
    "    # Compute cross entropy for each frame\n",
    "    cross_entropy = target * tf.log(output)\n",
    "    cross_entropy = -tf.reduce_sum(cross_entropy, 2)\n",
    "    mask = tf.sign(tf.reduce_max(tf.abs(target), 2))\n",
    "    cross_entropy *= mask\n",
    "    \n",
    "    # Average over actual sequence lengths\n",
    "    cross_entropy = tf.reduce_sum(cross_entropy, 1)\n",
    "    cross_entropy /= tf.reduce_sum(mask, 1)\n",
    "    \n",
    "    cost = tf.reduce_mane(cross_entropy)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code block calculate the loss using tf.gather_nd\n",
    "W_yh = tf.Variable(tf.random_normal([hl2_size, num_problems]), name=\"W_yh\")\n",
    "b_yh = tf.Variable(tf.constant(0.1, shape=[num_problems,]), name=\"b_yh\")\n",
    "\n",
    "last_layer_output = tf.reshape(hl2_output, [-1, hl2_size])\n",
    "logits_flat = tf.matmul(last_layer_output, W_yh) + b_yh\n",
    "preds_flat = tf.sigmoid(logits_flat)\n",
    "y_seq_flat = tf.cast(tf.reshape(y_seq, [-1, num_problems]), dtype=tf.float32)\n",
    "y_corr_flat = tf.cast(tf.reshape(y_corr, [-1, num_problems]), dtype=tf.float32)\n",
    "\n",
    "# get the indices where they are not equal to 0\n",
    "# the indices implies that a student has answered the question in the time step\n",
    "# and thereby exclude those time step that the student hasn't answered.\n",
    "target_indices = tf.where(tf.not_equal(y_seq_flat, 0))\n",
    "target_logits = tf.gather_nd(logits_flat, target_indices)\n",
    "target_preds = tf.gather_nd(preds_flat, target_indices)\n",
    "target_labels = tf.gather_nd(y_corr_flat, target_indices)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=target_logits, \n",
    "                                               labels=target_labels)\n",
    "total_loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(sess, print_loss=False):    \n",
    "    students = students_train\n",
    "    \n",
    "    best_test_auc = 0\n",
    "    best_epoch_idx = 0\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        \n",
    "        num_students = 10\n",
    "        num_students = len(students) \n",
    "\n",
    "        loss_train = 0\n",
    "        iteration = 1\n",
    "        \n",
    "        for batch_idx in range(0, num_students, batch_size):\n",
    "            start_idx = batch_idx\n",
    "            end_idx = min(num_students, batch_idx+batch_size)\n",
    "            \n",
    "            new_batch_size = end_idx - start_idx\n",
    "            \n",
    "            inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            \n",
    "            y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "            _optimizer, _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                    [optimizer, target_preds, target_labels, total_loss],\n",
    "                    feed_dict={\n",
    "                    inputs_seq: inputs_seq_batch,\n",
    "                    inputs_corr: inputs_corr_batch,\n",
    "                    targets_seq: y_seq_batch,\n",
    "                    targets_corr: y_corr_batch,\n",
    "                    keep_prob: 0.5,\n",
    "                })\n",
    "            \n",
    "            y_pred += [p for p in _target_preds]\n",
    "            y_true += [t for t in _target_labels]\n",
    "            loss_train = (iteration-1)/(iteration) * loss_train + _total_loss/iteration\n",
    "            iteration+=1\n",
    "        \n",
    "        # Print training information        \n",
    "        fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "        auc_train = auc(fpr, tpr)\n",
    "        print('Epoch {0:>4}, Train AUC: {1:.5}, Train Loss: {2:.5}'.format(epoch_idx+1, auc_train, loss_train))\n",
    "        \n",
    "        # evaluate on the test set\n",
    "        auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "        test_msg = \"Epoch {0:>4}, Test AUC: {1:.5}, Test Loss: {2:.5}\".format(epoch_idx+1, auc_test, loss_test)\n",
    "        if auc_test > best_test_auc:\n",
    "            test_msg += \"*\"\n",
    "            best_epoch_idx = epoch_idx\n",
    "            best_test_auc = auc_test\n",
    "            saver.save(sess=sess, save_path=save_path)\n",
    "        print(test_msg)\n",
    "        print(SPLIT_MSG)        \n",
    "        # quit the training if there is no improve in AUC for 20 epochs.\n",
    "        if epoch_idx - best_epoch_idx >= 20:\n",
    "            print(\"No improvement shown in 20 epochs. Quit Training.\")\n",
    "            break\n",
    "    \n",
    "    print(\"The best testing result occured at: {0}-th epoch, with testing AUC: {1:.5}\".format(best_epoch_idx, best_test_auc))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def evaluate(sess, is_train=False):    \n",
    "    if is_train:\n",
    "        students = students_train\n",
    "    else:\n",
    "        students = students_test\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    iteration = 1\n",
    "    _loss = 0\n",
    "    \n",
    "    num_students = 10\n",
    "    num_students = len(students)\n",
    "    \n",
    "    for batch_idx in range(0, num_students, batch_size):\n",
    "        start_idx = batch_idx\n",
    "        end_idx = min(num_students, batch_idx+batch_size)\n",
    "\n",
    "        new_batch_size = end_idx - start_idx\n",
    "\n",
    "        inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                [target_preds, target_labels, total_loss],\n",
    "                feed_dict={\n",
    "                inputs_seq: inputs_seq_batch,\n",
    "                inputs_corr: inputs_corr_batch,\n",
    "                targets_seq: y_seq_batch,\n",
    "                targets_corr: y_corr_batch,\n",
    "                keep_prob: 1,\n",
    "            })\n",
    "\n",
    "        y_pred += [p for p in _target_preds]\n",
    "        y_true += [t for t in _target_labels]\n",
    "        _loss = (iteration-1)/(iteration) * _loss + _total_loss/iteration\n",
    "        iteration+=1\n",
    "\n",
    "    fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return (auc_score, _loss)\n",
    "\n",
    "def get_student_output_layer(sess, student):\n",
    "    num_steps = len(student[1]) - 1\n",
    "    shape = (1, num_steps)\n",
    "    _inputs_seq = np.array(student[1][:-1]).reshape(shape)\n",
    "    _inputs_corr = np.array(student[2][:-1]).reshape(shape)\n",
    "    \n",
    "    _y_seq = np.array(student[1][1:]).reshape(shape)\n",
    "    _y_corr = np.array(student[2][1:]).reshape(shape)\n",
    "    \n",
    "    _preds_flat = sess.run(\n",
    "        preds_flat,\n",
    "        feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    )    \n",
    "    return _preds_flat\n",
    "\n",
    "def get_student_hidden_layer(sess, student, layer_num=1):\n",
    "    num_steps = len(student[1]) - 1\n",
    "    shape = (1, num_steps)\n",
    "    _inputs_seq = np.array(student[1][:-1]).reshape(shape)\n",
    "    _inputs_corr = np.array(student[2][:-1]).reshape(shape)\n",
    "    \n",
    "    _y_seq = np.array(student[1][1:]).reshape(shape)\n",
    "    _y_corr = np.array(student[2][1:]).reshape(shape)\n",
    "    \n",
    "    \n",
    "    feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    \n",
    "    result = None\n",
    "    if layer_num == 1:\n",
    "        result = sess.run(\n",
    "            hl1_output,\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    elif layer_num == 2:\n",
    "        result = sess.run(\n",
    "            hl2_output,\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    else:\n",
    "        print(\"layer is not available\")\n",
    "        return None\n",
    "    return result[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Define the tf saver\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/original_2hl_200_50/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WITH_CONFIG = True\n",
    "num_epochs = 1000\n",
    "\n",
    "### Start Training\n",
    "start_time = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "        print(\"Pre-trained model found, loading the previous variables\")\n",
    "    except:\n",
    "        print(\"Pre-trained model not found, train from scratch now.\")\n",
    "    optimize(sess)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"program run for: {0}s\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "In the following, the student output and hidden layer will be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved variable to the current session.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/original_2hl_200_50/model\n",
      "auc_test: 0.81488, loss_test: 0.81488\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"Loading the saved variable to the current session.\")\n",
    "saver.restore(sess=sess, save_path=save_path)\n",
    "\n",
    "auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "print (\"auc_test: {0:.5}, loss_test: {0:.5}\".format(auc_test, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer_1/rnn/lstm_cell/kernel:0' shape=(448, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer_1/rnn/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer_2/rnn/lstm_cell/kernel:0' shape=(250, 200) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer_2/rnn/lstm_cell/bias:0' shape=(200,) dtype=float32_ref>,\n",
       " <tf.Variable 'W_yh:0' shape=(50, 124) dtype=float32_ref>,\n",
       " <tf.Variable 'b_yh:0' shape=(124,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "#http://bokeh.pydata.org/en/0.10.0/docs/gallery/cat_heatmap_chart.html\n",
    "\n",
    "def plot_heatmap(data, x_labels, y_labels, second_x_labels=None, fig_size_inches=[15, 5]):\n",
    "#     plt.figure(figsize=(40,100))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(data, cmap=plt.cm.Blues)\n",
    "    \n",
    "    # Format\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    # turn off the frame\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(x_labels)) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(len(y_labels)) + 0.5, minor=False)\n",
    "    \n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    # set the label\n",
    "    ax.set_xticklabels(x_labels, minor=False)\n",
    "    ax.set_yticklabels(y_labels, minor=False)\n",
    "    ax.set_xlabel(\"the skill id answered at the time step\")\n",
    "    ax.set_ylabel(\"the skill id of the output layer\")\n",
    "\n",
    "    fig.set_size_inches(fig_size_inches[0], fig_size_inches[1])\n",
    "    \n",
    "    # second axis label\n",
    "    if second_x_labels != None:\n",
    "        ax2 = ax.twiny()\n",
    "        ax2.set_xticks(np.arange(len(second_x_labels)) + 0.5, minor=False)\n",
    "        ax2.set_xticklabels(second_x_labels)\n",
    "        ax2.set_xlabel(\"Correct Label\")\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 21, 38, 40, 71, 75, 81, 94, 98, 102, 106, 112, 115, 124, 147, 150, 154, 170, 180, 182, 187, 203, 205, 222, 224, 235, 243, 255, 276, 281, 285, 292, 294, 299, 311, 329, 335, 344, 345, 350, 367, 370, 371, 382, 393, 396, 409, 413, 431, 437, 443, 444, 460, 473, 485, 486, 491, 493, 497, 504, 506, 509, 511, 529, 531, 586, 593, 595, 599, 607, 615, 622, 626, 629, 631, 636, 645, 648, 651, 660, 661, 663, 685, 702, 722, 731, 733, 742, 757, 765, 767, 781]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "for i in range(len(students_test)):\n",
    "    student = students_test[i]\n",
    "    num_question_answered = student[0]\n",
    "    question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))\n",
    "    num_distict_question = len(question_ids_answered)\n",
    "    \n",
    "    if 50 >= num_question_answered >= 20 and 10 >= num_distict_question >= 5:\n",
    "        targets.append(i)\n",
    "    \n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# selecting one student to visualize\n",
    "sid = targets[2]\n",
    "student = students_test[sid]\n",
    "num_question_answered = student[0]\n",
    "question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "['105', '32', '47', '32', '44', '32', '44', '32', '42', '32', '42', '32', '44', '32', '44', '32', '39', '32', '44', '42', '42', '47', '42', '47', '47', '47', '42', '47', '42', '65', '65', '56', '53', '50', '65', '65', '65', '65', '65', '65', '65']\n",
      "['0', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '0', '0', '1', '1', '1', '0', '1', '0', '0', '0', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "output_layer = get_student_output_layer(sess, student)\n",
    "\n",
    "output_layer = output_layer[:num_question_answered, question_ids_answered]\n",
    "output_layer = np.transpose(output_layer)\n",
    "\n",
    "question_seq = student[1][:num_question_answered]\n",
    "correct_seq = student[2][:num_question_answered]\n",
    "\n",
    "print(num_question_answered),\n",
    "print(question_seq)\n",
    "print(correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAAFaCAYAAACuSeQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkNYDNnyRJkiQ1gM2fJEmSJDXA/wdLOoYqU17XvwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c839b8acc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(output_layer, x_labels=question_seq, y_labels=question_ids_answered, second_x_labels=correct_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hl1 = get_student_hidden_layer(sess, student=student, layer_num=1)\n",
    "hl1 = hl1[:num_question_answered]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(hl1)\n",
    "hl1_pca = pca.transform(hl1)\n",
    "pca_dim = len(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "hl1_pca.shape\n",
    "hl1_pca = np.transpose(hl1_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hl1_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_heatmap(hl1_pca, x_labels=question_seq, y_labels=range(pca_dim), second_x_labels=correct_seq, fig_size_inches=[15, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(hl1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hl2 = get_student_hidden_layer(sess, student=student, layer_num=2)\n",
    "hl2 = hl2[:num_question_answered]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(hl2)\n",
    "hl1_pca = pca.transform(hl1)\n",
    "pca_dim = len(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "hl1_pca.shape\n",
    "hl1_pca = np.transpose(hl1_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
