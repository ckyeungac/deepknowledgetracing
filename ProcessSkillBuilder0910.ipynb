{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "The skill builder dataset has 30 columns.\n",
    "Please refer to this [link](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data) for detail description.\n",
    "\n",
    "**The relevant columns are:**\n",
    "- order_id: it is chronological.\n",
    "- user_id: the id of the student doing the problem.\n",
    "- problem_id: the id of the problem\n",
    "- correct: 1 means correct on the first attempt, 0 means incorrect on the first attempt, or asked for help\n",
    "\n",
    "**The following columns are useful but may not be used for DKT:**\n",
    "- skill_id: the skill associated with the problem. \n",
    "- **orginal: 1 means main problem, 0 means scaffolding problem**\n",
    "    - It is required to determine whether to include scaffolding\n",
    "- ms_first_response: The time in milliseconds for the student's first response.\n",
    "- hint_count: number of student attempts on this problem.\n",
    "- attempt_count: number of student attmepts on this problem.\n",
    "\n",
    "---\n",
    "The following code will use numpy and pandas to process the **2009-2010 ASSISTment Data** so as to convert it into a tensorflow-friendly data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YEUNG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2825: DtypeWarning: Columns (17,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "file_path = './data/skill_builder_data.csv'\n",
    "\n",
    "# encoding are required as it is not utf8 encoded.\n",
    "data = pd.DataFrame.from_csv(file_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this dataset, there are 525534 records, with 4217 students and 26688 different questions.\n",
      "With the following columns: \n",
      " Index(['assignment_id', 'user_id', 'assistment_id', 'problem_id', 'original',\n",
      "       'correct', 'attempt_count', 'ms_first_response', 'tutor_mode',\n",
      "       'answer_type', 'sequence_id', 'student_class_id', 'position', 'type',\n",
      "       'base_sequence_id', 'skill_id', 'skill_name', 'teacher_id', 'school_id',\n",
      "       'hint_count', 'hint_total', 'overlap_time', 'template_id', 'answer_id',\n",
      "       'answer_text', 'first_action', 'bottom_hint', 'opportunity',\n",
      "       'opportunity_original'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_users = len(data.user_id.unique())\n",
    "num_problems = len(data.problem_id.unique())\n",
    "num_records = data.shape[0]\n",
    "msg = \"In this dataset, there are {0} records, with {1} students and {2} \\\n",
    "different questions.\"\n",
    "print(msg.format(num_records, num_users, num_problems))\n",
    "print(\"With the following columns: \\n\", data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data\n",
    "1. Filter out students with exactly one interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_id_to_idx_dict(df, column):\n",
    "    ids = df[column].unique()\n",
    "    num_unique_ids = len(ids)\n",
    "    id_to_idx_dict = dict(zip(ids, range(num_unique_ids)))\n",
    "    return id_to_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data shape after remove nan: (459208, 30)\n",
      "The data shape after remove duplicated records: (338001, 30)\n"
     ]
    }
   ],
   "source": [
    "REQUIRE_COLS = ['time_idx', 'user_id', 'problem_id', 'correct']\n",
    "\n",
    "# get the time index\n",
    "data['time_idx'] = data.index.values\n",
    "data.head()\n",
    "\n",
    "# remove nan in skill_id\n",
    "nan_records = data.skill_id.apply(np.isnan)\n",
    "data = data[~nan_records]\n",
    "print(\"The data shape after remove nan:\", data.shape)\n",
    "\n",
    "# remove duplicated records\n",
    "columns = set(data.columns.values)\n",
    "columns.remove('opportunity')\n",
    "columns.remove('opportunity_original')\n",
    "columns = list(columns)\n",
    "data = data[~data.duplicated(subset=columns)]\n",
    "print(\"The data shape after remove duplicated records:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ids = data.user_id.unique()\n",
    "problem_to_idx_dict = generate_id_to_idx_dict(data, column='problem_id')\n",
    "\n",
    "tuples = []\n",
    "for id in user_ids:\n",
    "    df = data[data.user_id == id]\n",
    "    df = df[REQUIRE_COLS]\n",
    "    problems = [problem_to_idx_dict[pid] for pid in df.problem_id]\n",
    "    corrects = [corr for corr in df.correct]\n",
    "    num_problems = len(problems)\n",
    "#     print (num_problems)\n",
    "#     print (problems)\n",
    "#     print (corrects)\n",
    "#     print (\"============\")\n",
    "    result = (num_problems, problems, corrects)\n",
    "    tuples.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/temp.csv', 'w') as f:\n",
    "    writer = csv.writer(f, \n",
    "                        delimiter=',', \n",
    "                        quotechar=\"'\", \n",
    "                        quoting=csv.QUOTE_MINIMAL,\n",
    "                        lineterminator='\\n')\n",
    "    for tup in tuples:\n",
    "        writer.writerow([tup[0]])\n",
    "        writer.writerow(tup[1])\n",
    "        writer.writerow(tup[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4217"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
