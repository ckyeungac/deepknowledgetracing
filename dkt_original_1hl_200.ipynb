{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from utils import load_train_test\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# specify the gpu device\n",
    "# import os\n",
    "# from Tools.utils import _make_dir, load_options\n",
    "# options = load_options('options.json')\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"OCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "SPLIT_MSG=\"***********\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './data/'\n",
    "train_file = '0910_b_train.csv'\n",
    "test_file = '0910_b_test.csv'\n",
    "train_path= os.path.join(DATA_DIR, train_file)\n",
    "test_path = os.path.join(DATA_DIR, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ./data/0910_b_train.csv\n",
      "10116 lines was read\n",
      "max_num_problems_answered: 1219\n",
      "num_problems: 124\n",
      "The number of students is 3134\n",
      "Finish reading data.\n",
      "Reading ./data/0910_b_test.csv\n",
      "2532 lines was read\n",
      "max_num_problems_answered: 1062\n",
      "num_problems: 124\n",
      "The number of students is 786\n",
      "Finish reading data.\n"
     ]
    }
   ],
   "source": [
    "students_train, students_test, max_num_steps, num_problems = load_train_test(train_path, test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Model\n",
    "\n",
    "### Placeholder Explanation\n",
    "X is the one-hot encoded input sequence of a student.\n",
    "y is the one-hot encoded correct sequence of a student.\n",
    "\n",
    "For example, the student i has a seq [1, 3, 1, 1, 2] with correct map [0, 1, 1, 1, 0]. The X_seq will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The X_corr map will be one hot encoded as:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&0&0\\\\\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "Then, it will be concatenated into $X^i$:\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc|ccccc}\n",
    "        0&1&0&0&0&0&0&0&0&0\\\\\n",
    "        0&0&0&1&0&0&0&0&1&0\\\\\n",
    "        0&1&0&0&0&0&1&0&0&0\\\\\n",
    "        0&1&0&0&0&0&1&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "The last question '2' is not used in the $X^i$ because it is the last record that the student has and therefore used in $y$.\n",
    "So, $y$ would be seq [3, 1, 1, 2] with corr map [1, 1, 1, 0]\n",
    "$$\n",
    "\\left[\n",
    "    \\begin{array}{ccccc}\n",
    "        0&0&0&1&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&1&0&0&0\\\\\n",
    "        0&0&0&0&0\\\\\n",
    "    \\end{array}\n",
    "\\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_corr_to_onehot(seq, corr, num_steps, num_problems):\n",
    "    seq_oh = tf.one_hot(seq, depth=num_problems)\n",
    "    seq_oh_flat = tf.reshape(seq_oh, [-1, num_problems])\n",
    "    \n",
    "    # element-wise multiplication between Matrix and Vector\n",
    "    # the i-th column of Matrixelement-wisedly multiply the i-th element in the Vector\n",
    "    corr_flat = tf.reshape(corr, [-1])\n",
    "    corr_mat = tf.multiply(tf.transpose(seq_oh_flat), tf.cast(corr_flat, dtype=tf.float32))\n",
    "    corr_mat = tf.transpose(corr_mat)\n",
    "    corr_mat = tf.reshape(corr_mat, shape=[-1, num_steps, num_problems])\n",
    "    \n",
    "    concat = tf.concat([seq_oh, corr_mat], axis=2)\n",
    "    \n",
    "    return seq_oh, corr_mat, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "    length = tf.reduce_sum(used, 1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# network configuration\n",
    "batch_size = 64\n",
    "max_num_steps = max_num_steps - 1\n",
    "num_problems = num_problems\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "inputs_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "inputs_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "X_seq, X_corr, X = seq_corr_to_onehot(inputs_seq, inputs_corr, max_num_steps, num_problems)\n",
    "\n",
    "targets_seq = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "targets_corr = tf.placeholder(tf.int32, [None, max_num_steps])\n",
    "y_seq, y_corr, _ = seq_corr_to_onehot(targets_seq, targets_corr, max_num_steps, num_problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1218), Dimension(248)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build up the network\n",
    "hl1_size = 200\n",
    "sequence_length = length(X_seq)\n",
    "\n",
    "with tf.variable_scope('hidden_layer_1'):\n",
    "    hl1_cell = tf.contrib.rnn.LSTMCell(num_units=hl1_size)\n",
    "    hl1_cell = tf.contrib.rnn.DropoutWrapper(hl1_cell, output_keep_prob=keep_prob)\n",
    "    hl1_output, hl1_state = tf.nn.dynamic_rnn(\n",
    "        hl1_cell,\n",
    "        X,\n",
    "        dtype=tf.float32,\n",
    "#         sequence_length=sequence_length\n",
    "    )\n",
    "\n",
    "last_layer_size = hl1_size\n",
    "last_layer_output, last_layer_state = hl1_output, hl1_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this code block calculate the loss using tf.gather_nd\n",
    "W_yh = tf.Variable(tf.random_normal([last_layer_size, num_problems]), name=\"W_yh\")\n",
    "b_yh = tf.Variable(tf.constant(0.1, shape=[num_problems,]), name=\"b_yh\")\n",
    "\n",
    "last_layer_output_flat = tf.reshape(last_layer_output, [-1, last_layer_size])\n",
    "logits_flat = tf.matmul(last_layer_output_flat, W_yh) + b_yh\n",
    "preds_flat = tf.sigmoid(logits_flat)\n",
    "y_seq_flat = tf.cast(tf.reshape(y_seq, [-1, num_problems]), dtype=tf.float32)\n",
    "y_corr_flat = tf.cast(tf.reshape(y_corr, [-1, num_problems]), dtype=tf.float32)\n",
    "\n",
    "# get the indices where they are not equal to 0\n",
    "# the indices implies that a student has answered the question in the time step\n",
    "# and thereby exclude those time step that the student hasn't answered.\n",
    "target_indices = tf.where(tf.not_equal(y_seq_flat, 0))\n",
    "target_logits = tf.gather_nd(logits_flat, target_indices)\n",
    "target_preds = tf.gather_nd(preds_flat, target_indices)\n",
    "target_labels = tf.gather_nd(y_corr_flat, target_indices)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=target_logits, \n",
    "                                               labels=target_labels)\n",
    "total_loss = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(sess, print_loss=False):    \n",
    "    students = students_train\n",
    "    \n",
    "    best_test_auc = 0\n",
    "    best_epoch_idx = 0\n",
    "    for epoch_idx in range(num_epochs):\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        \n",
    "        num_students = 10\n",
    "        num_students = len(students) \n",
    "\n",
    "        loss_train = 0\n",
    "        iteration = 1\n",
    "        \n",
    "        for batch_idx in range(0, num_students, batch_size):\n",
    "            start_idx = batch_idx\n",
    "            end_idx = min(num_students, batch_idx+batch_size)\n",
    "            \n",
    "            new_batch_size = end_idx - start_idx\n",
    "            \n",
    "            inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            \n",
    "            y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "            y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "            _optimizer, _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                    [optimizer, target_preds, target_labels, total_loss],\n",
    "                    feed_dict={\n",
    "                    inputs_seq: inputs_seq_batch,\n",
    "                    inputs_corr: inputs_corr_batch,\n",
    "                    targets_seq: y_seq_batch,\n",
    "                    targets_corr: y_corr_batch,\n",
    "                    keep_prob: 0.5,\n",
    "                })\n",
    "            \n",
    "            y_pred += [p for p in _target_preds]\n",
    "            y_true += [t for t in _target_labels]\n",
    "            loss_train = (iteration-1)/(iteration) * loss_train + _total_loss/iteration\n",
    "            iteration+=1\n",
    "        \n",
    "        # Print training information        \n",
    "        fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "        auc_train = auc(fpr, tpr)\n",
    "        print('Epoch {0:>4}, Train AUC: {1:.5}, Train Loss: {2:.5}'.format(epoch_idx+1, auc_train, loss_train))\n",
    "        \n",
    "        # evaluate on the test set\n",
    "        auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "        test_msg = \"Epoch {0:>4}, Test AUC: {1:.5}, Test Loss: {2:.5}\".format(epoch_idx+1, auc_test, loss_test)\n",
    "        if auc_test > best_test_auc:\n",
    "            test_msg += \"*\"\n",
    "            best_epoch_idx = epoch_idx\n",
    "            best_test_auc = auc_test\n",
    "            saver.save(sess=sess, save_path=save_path)\n",
    "        print(test_msg)\n",
    "        print(SPLIT_MSG)        \n",
    "        # quit the training if there is no improve in AUC for 20 epochs.\n",
    "        if epoch_idx - best_epoch_idx >= 20:\n",
    "            print(\"No improvement shown in 20 epochs. Quit Training.\")\n",
    "            break\n",
    "    print(\"The best testing result occured at: {0}-th epoch, with testing AUC: {1:.5}\".format(best_epoch_idx, best_test_auc))\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def evaluate(sess, is_train=False):    \n",
    "    if is_train:\n",
    "        students = students_train\n",
    "    else:\n",
    "        students = students_test\n",
    "    \n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    iteration = 1\n",
    "    _loss = 0\n",
    "    \n",
    "    num_students = 10\n",
    "    num_students = len(students)\n",
    "    \n",
    "    for batch_idx in range(0, num_students, batch_size):\n",
    "        start_idx = batch_idx\n",
    "        end_idx = min(num_students, batch_idx+batch_size)\n",
    "\n",
    "        new_batch_size = end_idx - start_idx\n",
    "\n",
    "        inputs_seq_batch = np.array([tup[1][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        inputs_corr_batch = np.array([tup[2][:-1] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        y_seq_batch = np.array([tup[1][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "        y_corr_batch = np.array([tup[2][1:] for tup in students[start_idx:end_idx]], dtype=np.int32)\n",
    "\n",
    "        _target_preds, _target_labels, _total_loss = sess.run(\n",
    "                [target_preds, target_labels, total_loss],\n",
    "                feed_dict={\n",
    "                inputs_seq: inputs_seq_batch,\n",
    "                inputs_corr: inputs_corr_batch,\n",
    "                targets_seq: y_seq_batch,\n",
    "                targets_corr: y_corr_batch,\n",
    "                keep_prob: 1,\n",
    "            })\n",
    "\n",
    "        y_pred += [p for p in _target_preds]\n",
    "        y_true += [t for t in _target_labels]\n",
    "        _loss = (iteration-1)/(iteration) * _loss + _total_loss/iteration\n",
    "        iteration+=1\n",
    "\n",
    "    fpr, tpr, thres = roc_curve(y_true, y_pred, pos_label=1)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    return (auc_score, _loss)\n",
    "\n",
    "def get_student_output_layer(sess, student):\n",
    "    num_steps = len(student[1]) - 1\n",
    "    shape = (1, num_steps)\n",
    "    _inputs_seq = np.array(student[1][:-1]).reshape(shape)\n",
    "    _inputs_corr = np.array(student[2][:-1]).reshape(shape)\n",
    "    \n",
    "    _y_seq = np.array(student[1][1:]).reshape(shape)\n",
    "    _y_corr = np.array(student[2][1:]).reshape(shape)\n",
    "    \n",
    "    _preds_flat = sess.run(\n",
    "        preds_flat,\n",
    "        feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    )    \n",
    "    return _preds_flat\n",
    "\n",
    "def get_student_hidden_layer(sess, student, layer_num=1):\n",
    "    _inputs_seq = np.array(tup[1][:-1])\n",
    "    _inputs_corr = np.array(tup[2][:-1])\n",
    "    \n",
    "    _y_seq = np.array(tup[1][1:])\n",
    "    _y_corr = np.array(tup[2][1:])\n",
    "    \n",
    "    feed_dict={\n",
    "            inputs_seq: _inputs_seq,\n",
    "            inputs_corr: _inputs_corr,\n",
    "            targets_seq: _y_seq,\n",
    "            targets_corr: _y_corr,\n",
    "            keep_prob: 1,\n",
    "        }\n",
    "    \n",
    "    result = None\n",
    "    if layer_num == 1:\n",
    "        result = sess.run(\n",
    "            [hl1_output],\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    elif layer_num == 2:\n",
    "        result = sess.run(\n",
    "            [hl2_output],\n",
    "            feed_dict=feed_dict,\n",
    "        )\n",
    "    else:\n",
    "        print(\"layer is not available\")\n",
    "        return None\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define the tf saver\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/original/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WITH_CONFIG = True\n",
    "num_epochs = 1000\n",
    "\n",
    "### Start Training\n",
    "start_time = time.time()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    try:\n",
    "        saver.restore(sess=sess, save_path=save_path)\n",
    "        print(\"Pre-trained model found, loading the previous variables\")\n",
    "    except:\n",
    "        print(\"Pre-trained model not found, train from scratch now.\")\n",
    "    optimize(sess)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"program run for: {0}s\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "In the following, the student output and hidden layer will be visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved variable to the current session.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/original/model\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"Loading the saved variable to the current session.\")\n",
    "saver.restore(sess=sess, save_path=save_path)\n",
    "\n",
    "auc_test, loss_test = evaluate(sess, is_train=False)\n",
    "print (\"auc_test: {0:.5}, loss_test: {0:.5}\".format(auc_test, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden_layer_1/rnn/lstm_cell/kernel:0' shape=(448, 800) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden_layer_1/rnn/lstm_cell/bias:0' shape=(800,) dtype=float32_ref>,\n",
       " <tf.Variable 'W_yh:0' shape=(200, 124) dtype=float32_ref>,\n",
       " <tf.Variable 'b_yh:0' shape=(124,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline\n",
    "#http://bokeh.pydata.org/en/0.10.0/docs/gallery/cat_heatmap_chart.html\n",
    "\n",
    "def plot_heatmap(data, x_labels, y_labels, second_x_labels=None, fig_size_inches=[15, 5]):\n",
    "#     plt.figure(figsize=(40,100))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    heatmap = ax.pcolor(data, cmap=plt.cm.Blues)\n",
    "    \n",
    "    # Format\n",
    "    fig = plt.gcf()\n",
    "    \n",
    "    # turn off the frame\n",
    "    ax.set_frame_on(False)\n",
    "    \n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(x_labels)) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(len(y_labels)) + 0.5, minor=False)\n",
    "    \n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    \n",
    "    # set the label\n",
    "    ax.set_xticklabels(x_labels, minor=False)\n",
    "    ax.set_yticklabels(y_labels, minor=False)\n",
    "    ax.set_xlabel(\"the skill id answered at the time step\")\n",
    "    ax.set_ylabel(\"the skill id of the output layer\")\n",
    "\n",
    "    fig.set_size_inches(fig_size_inches[0], fig_size_inches[1])\n",
    "    \n",
    "    # second axis label\n",
    "    if second_x_labels != None:\n",
    "        ax2 = ax.twiny()\n",
    "        ax2.set_xticks(np.arange(len(second_x_labels)) + 0.5, minor=False)\n",
    "        ax2.set_xticklabels(second_x_labels)\n",
    "        ax2.set_xlabel(\"Correct Label\")\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 21, 38, 40, 71, 75, 81, 94, 98, 102, 106, 112, 115, 124, 147, 150, 154, 170, 180, 182, 187, 203, 205, 222, 224, 235, 243, 255, 276, 281, 285, 292, 294, 299, 311, 329, 335, 344, 345, 350, 367, 370, 371, 382, 393, 396, 409, 413, 431, 437, 443, 444, 460, 473, 485, 486, 491, 493, 497, 504, 506, 509, 511, 529, 531, 586, 593, 595, 599, 607, 615, 622, 626, 629, 631, 636, 645, 648, 651, 660, 661, 663, 685, 702, 722, 731, 733, 742, 757, 765, 767, 781]\n"
     ]
    }
   ],
   "source": [
    "targets = []\n",
    "for i in range(len(students_test)):\n",
    "    student = students_test[i]\n",
    "    num_question_answered = student[0]\n",
    "    question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))\n",
    "    num_distict_question = len(question_ids_answered)\n",
    "    \n",
    "    if 50 >= num_question_answered >= 20 and 10 >= num_distict_question >= 5:\n",
    "        targets.append(i)\n",
    "    \n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting one student to visualize\n",
    "sid = targets[-6]\n",
    "student = students_test[sid]\n",
    "num_question_answered = student[0]\n",
    "question_ids_answered = np.sort(np.array([int(qid) for qid in set(student[1]) if qid != -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "['37', '37', '41', '36', '41', '36', '37', '37', '72', '37', '72', '37', '41', '36', '41', '36', '41', '36', '41', '36', '41', '36', '41', '36', '41', '36', '36', '36', '37', '37', '41', '36', '70']\n",
      "['1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '1', '1', '0', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']\n"
     ]
    }
   ],
   "source": [
    "output_layer = get_student_output_layer(sess, student)\n",
    "\n",
    "output_layer = output_layer[:num_question_answered, question_ids_answered]\n",
    "output_layer = np.transpose(output_layer)\n",
    "\n",
    "question_seq = student[1][:num_question_answered]\n",
    "correct_seq = student[2][:num_question_answered]\n",
    "\n",
    "print(num_question_answered),\n",
    "print(question_seq)\n",
    "print(correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAFaCAYAAABMlf9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wP8PL7Y42cj9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x245031e7e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_heatmap(output_layer, x_labels=question_seq, y_labels=question_ids_answered, second_x_labels=correct_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
