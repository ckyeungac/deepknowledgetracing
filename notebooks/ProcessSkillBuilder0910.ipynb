{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "The skill builder dataset has 30 columns.\n",
    "Please refer to this [link](https://sites.google.com/site/assistmentsdata/home/assistment-2009-2010-data) for detail description.\n",
    "\n",
    "**The relevant columns are:**\n",
    "- order_id: it is chronological.\n",
    "- user_id: the id of the student doing the problem.\n",
    "- problem_id: the id of the problem\n",
    "- correct: 1 means correct on the first attempt, 0 means incorrect on the first attempt, or asked for help\n",
    "\n",
    "**The following columns are useful but may not be used for DKT:**\n",
    "- skill_id: the skill associated with the problem. \n",
    "- **orginal: 1 means main problem, 0 means scaffolding problem**\n",
    "    - It is required to determine whether to include scaffolding\n",
    "- ms_first_response: The time in milliseconds for the student's first response.\n",
    "- hint_count: number of student attempts on this problem.\n",
    "- attempt_count: number of student attmepts on this problem.\n",
    "\n",
    "---\n",
    "The following code will use numpy and pandas to process the **2009-2010 ASSISTment Data** so as to convert it into a tensorflow-friendly data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YEUNG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2825: DtypeWarning: Columns (17,29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "file_path = './data/skill_builder_data.csv'\n",
    "\n",
    "scaffolding = False\n",
    "empty_skill = True\n",
    "\n",
    "# encoding are required as it is not utf8 encoded.\n",
    "data = pd.DataFrame.from_csv(file_path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this dataset, there are 525534 records, with 4217 students and 26688 different questions.\n",
      "With the following columns: \n",
      " Index(['assignment_id', 'user_id', 'assistment_id', 'problem_id', 'original',\n",
      "       'correct', 'attempt_count', 'ms_first_response', 'tutor_mode',\n",
      "       'answer_type', 'sequence_id', 'student_class_id', 'position', 'type',\n",
      "       'base_sequence_id', 'skill_id', 'skill_name', 'teacher_id', 'school_id',\n",
      "       'hint_count', 'hint_total', 'overlap_time', 'template_id', 'answer_id',\n",
      "       'answer_text', 'first_action', 'bottom_hint', 'opportunity',\n",
      "       'opportunity_original'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_users = len(data.user_id.unique())\n",
    "num_problems = len(data.problem_id.unique())\n",
    "num_records = data.shape[0]\n",
    "msg = \"In this dataset, there are {0} records, with {1} students and {2} \\\n",
    "different questions.\"\n",
    "print(msg.format(num_records, num_users, num_problems))\n",
    "print(\"With the following columns: \\n\", data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the data\n",
    "1. Filter out students with exactly one interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_id_to_idx_dict(df, column):\n",
    "    ids = df[column].unique()\n",
    "    num_unique_ids = len(ids)\n",
    "    id_to_idx_dict = dict(zip(ids, range(num_unique_ids)))\n",
    "    return id_to_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data shape after remove scaffording: (449220, 30)\n",
      "The data shape after remove duplicated records: (328291, 30)\n"
     ]
    }
   ],
   "source": [
    "REQUIRE_COLS = ['time_idx', 'user_id', 'skill_id', 'correct']\n",
    "\n",
    "# get the time index\n",
    "data['time_idx'] = data.index.values\n",
    "data.head()\n",
    "\n",
    "# remove nan in skill_id\n",
    "if not empty_skill:\n",
    "    # remove nan in skill_id\n",
    "    nan_records = data.skill_id.apply(np.isnan)\n",
    "    data = data[~nan_records]\n",
    "    print(\"The data shape after remove nan:\", data.shape)\n",
    "else:\n",
    "    # replace nan with 0 in skill_id\n",
    "    data['skill_id'] = data['skill_id'].fillna(0)\n",
    "\n",
    "if not scaffolding:\n",
    "    data = data[data.original == 1]\n",
    "    print(\"The data shape after remove scaffording:\", data.shape)\n",
    "    \n",
    "\n",
    "# remove duplicated records\n",
    "columns = set(data.columns.values)\n",
    "columns.remove('opportunity')\n",
    "columns.remove('opportunity_original')\n",
    "columns = list(columns)\n",
    "data = data[~data.duplicated(subset=columns)]\n",
    "print(\"The data shape after remove duplicated records:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1.,    2.,    4.,    5.,    8.,    9.,   10.,   11.,   12.,\n",
       "         13.,   14.,   15.,   16.,   17.,   18.,   21.,   22.,   24.,\n",
       "         25.,   26.,   27.,   32.,   34.,   35.,   37.,   39.,   40.,\n",
       "         42.,   43.,   46.,   47.,   48.,   49.,   50.,   51.,   53.,\n",
       "         54.,   58.,   61.,   63.,   64.,   65.,   67.,   69.,   70.,\n",
       "         74.,   75.,   76.,   77.,   79.,   80.,   81.,   82.,   83.,\n",
       "         84.,   85.,   86.,   91.,   92.,   94.,   96.,   97.,   99.,\n",
       "        101.,  102.,  104.,  105.,  110.,  163.,  165.,  166.,  173.,\n",
       "        190.,  193.,  203.,  204.,  217.,  221.,  276.,  277.,  278.,\n",
       "        279.,  280.,  290.,  292.,  293.,  294.,  295.,  296.,  297.,\n",
       "        298.,  299.,  301.,  303.,  307.,  308.,  309.,  310.,  311.,\n",
       "        312.,  314.,  317.,  321.,  322.,  323.,  324.,  325.,  331.,\n",
       "        333.,  334.,  340.,  343.,  346.,  348.,  350.,  356.,  362.,\n",
       "        365.,  367.,  368.,  371.,  375.,  378.,    0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.skill_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skill_df = data[['skill_id', 'skill_name']].drop_duplicates()\n",
    "idx_to_problem_dict = {}\n",
    "for index, row in skill_df.iterrows():\n",
    "    skill_idx = problem_to_idx_dict[row['skill_id']]\n",
    "    idx_to_problem_dict[skill_idx] = (row['skill_id'], row['skill_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1.0, 'Box and Whisker')\n",
      "1 (2.0, 'Circle Graph')\n",
      "2 (4.0, 'Histogram as Table or Graph')\n",
      "3 (5.0, 'Number Line')\n",
      "4 (8.0, 'Scatter Plot')\n",
      "5 (9.0, 'Stem and Leaf Plot')\n",
      "6 (10.0, 'Table')\n",
      "7 (11.0, 'Venn Diagram')\n",
      "8 (12.0, 'Mean')\n",
      "9 (13.0, 'Median')\n",
      "10 (14.0, 'Mode')\n",
      "11 (15.0, 'Range')\n",
      "12 (16.0, 'Counting Methods')\n",
      "13 (17.0, 'Probability of Two Distinct Events')\n",
      "14 (18.0, 'Probability of a Single Event')\n",
      "15 (21.0, 'Interior Angles Figures with More than 3 Sides')\n",
      "16 (22.0, 'Interior Angles Triangle')\n",
      "17 (24.0, 'Congruence')\n",
      "18 (25.0, 'Complementary and Supplementary Angles')\n",
      "19 (26.0, 'Angles on Parallel Lines Cut by a Transversal')\n",
      "20 (27.0, 'Pythagorean Theorem')\n",
      "21 (32.0, 'Nets of 3D Figures')\n",
      "22 (34.0, 'Unit Conversion Within a System')\n",
      "23 (35.0, 'Effect of Changing Dimensions of a Shape Prportionally')\n",
      "24 (37.0, nan)\n",
      "25 (39.0, 'Area Circle')\n",
      "26 (40.0, 'Circumference ')\n",
      "27 (42.0, 'Perimeter of a Polygon')\n",
      "28 (43.0, 'Reading a Ruler or Scale')\n",
      "29 (46.0, 'Calculations with Similar Figures')\n",
      "30 (47.0, 'Conversion of Fraction Decimals Percents')\n",
      "31 (48.0, 'Equivalent Fractions')\n",
      "32 (49.0, 'Ordering Positive Decimals')\n",
      "33 (50.0, 'Ordering Fractions')\n",
      "34 (51.0, 'Ordering Integers')\n",
      "35 (53.0, 'Ordering Real Numbers')\n",
      "36 (54.0, 'Rounding')\n",
      "37 (58.0, 'Addition Whole Numbers')\n",
      "38 (61.0, 'Division Fractions')\n",
      "39 (63.0, 'Estimation')\n",
      "40 (64.0, 'Fraction Of')\n",
      "41 (65.0, 'Least Common Multiple')\n",
      "42 (67.0, 'Multiplication Fractions')\n",
      "43 (69.0, 'Multiplication Whole Numbers')\n",
      "44 (70.0, 'Percent Of')\n",
      "45 (74.0, 'Subtraction Whole Numbers')\n",
      "46 (75.0, 'Square Root')\n",
      "47 (76.0, nan)\n",
      "48 (77.0, 'Finding Percents')\n",
      "49 (79.0, 'Proportion')\n",
      "50 (80.0, 'Scale Factor')\n",
      "51 (81.0, 'Unit Rate')\n",
      "52 (82.0, 'Scientific Notation')\n",
      "53 (83.0, 'Divisibility Rules')\n",
      "54 (84.0, 'Prime Number')\n",
      "55 (85.0, 'Absolute Value')\n",
      "56 (86.0, 'Exponents')\n",
      "57 (91.0, nan)\n",
      "58 (92.0, 'Pattern Finding ')\n",
      "59 (94.0, nan)\n",
      "60 (96.0, nan)\n",
      "61 (97.0, nan)\n",
      "62 (99.0, nan)\n",
      "63 (101.0, nan)\n",
      "64 (102.0, nan)\n",
      "65 (104.0, nan)\n",
      "66 (105.0, nan)\n",
      "67 (110.0, 'D.4.8-understanding-concept-of-probabilities')\n",
      "68 (163.0, 'Absolute Value')\n",
      "69 (165.0, 'Algebraic Simplification')\n",
      "70 (166.0, 'Algebraic Solving')\n",
      "71 (173.0, 'Choose an Equation from Given Information')\n",
      "72 (190.0, 'Intercept')\n",
      "73 (193.0, 'Linear Equations')\n",
      "74 (203.0, 'Percent Discount')\n",
      "75 (204.0, 'Percents')\n",
      "76 (217.0, 'Rate')\n",
      "77 (221.0, 'Slope')\n",
      "78 (276.0, 'Multiplication and Division Positive Decimals')\n",
      "79 (277.0, 'Addition and Subtraction Integers')\n",
      "80 (278.0, 'Addition and Subtraction Positive Decimals')\n",
      "81 (279.0, 'Multiplication and Division Integers')\n",
      "82 (280.0, 'Addition and Subtraction Fractions')\n",
      "83 (290.0, 'Reflection')\n",
      "84 (292.0, 'Rotations')\n",
      "85 (293.0, 'Translations')\n",
      "86 (294.0, 'Area Irregular Figure')\n",
      "87 (295.0, 'Area Parallelogram')\n",
      "88 (296.0, 'Area Rectangle')\n",
      "89 (297.0, 'Area Trapezoid')\n",
      "90 (298.0, 'Area Triangle')\n",
      "91 (299.0, 'Surface Area Cylinder')\n",
      "92 (301.0, 'Surface Area Rectangular Prism')\n",
      "93 (303.0, 'Volume Cylinder')\n",
      "94 (307.0, 'Volume Rectangular Prism')\n",
      "95 (308.0, 'Volume Sphere')\n",
      "96 (309.0, 'Order of Operations +,-,/,* () positive reals')\n",
      "97 (310.0, 'Order of Operations All')\n",
      "98 (311.0, 'Equation Solving Two or Fewer Steps')\n",
      "99 (312.0, 'Equation Solving More Than Two Steps')\n",
      "100 (314.0, 'Angles - Obtuse, Acute, and Right')\n",
      "101 (317.0, 'Greatest Common Factor')\n",
      "102 (321.0, 'Computation with Real Numbers')\n",
      "103 (322.0, 'Write Linear Equation from Ordered Pairs')\n",
      "104 (323.0, 'Write Linear Equation from Situation')\n",
      "105 (324.0, 'Recognize Linear Pattern')\n",
      "106 (325.0, 'Write Linear Equation from Graph')\n",
      "107 (331.0, 'Finding Slope From Situation')\n",
      "108 (333.0, 'Finding Slope From Equation')\n",
      "109 (334.0, 'Finding Slope from Ordered Pairs')\n",
      "110 (340.0, 'Distributive Property')\n",
      "111 (343.0, 'Midpoint')\n",
      "112 (346.0, 'Polynomial Factors')\n",
      "113 (348.0, 'Recognize Quadratic Pattern')\n",
      "114 (350.0, 'Solving Systems of Linear Equations')\n",
      "115 (356.0, 'Quadratic Formula to Solve Quadratic Equation')\n",
      "116 (362.0, 'Parts of a Polyomial, Terms, Coefficient, Monomial, Exponent, Variable')\n",
      "117 (365.0, 'Interpreting Coordinate Graphs ')\n",
      "118 (367.0, nan)\n",
      "119 (368.0, 'Solving for a variable')\n",
      "120 (371.0, 'Simplifying Expressions positive exponents')\n",
      "121 (375.0, 'Solving Inequalities')\n",
      "122 (378.0, 'Solving Systems of Linear Equations by Graphing')\n",
      "123 (0.0, nan)\n"
     ]
    }
   ],
   "source": [
    "for key, value in idx_to_problem_dict.items():\n",
    "    print (key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 123,\n",
       " 1.0: 0,\n",
       " 2.0: 1,\n",
       " 4.0: 2,\n",
       " 5.0: 3,\n",
       " 8.0: 4,\n",
       " 9.0: 5,\n",
       " 10.0: 6,\n",
       " 11.0: 7,\n",
       " 12.0: 8,\n",
       " 13.0: 9,\n",
       " 14.0: 10,\n",
       " 15.0: 11,\n",
       " 16.0: 12,\n",
       " 17.0: 13,\n",
       " 18.0: 14,\n",
       " 21.0: 15,\n",
       " 22.0: 16,\n",
       " 24.0: 17,\n",
       " 25.0: 18,\n",
       " 26.0: 19,\n",
       " 27.0: 20,\n",
       " 32.0: 21,\n",
       " 34.0: 22,\n",
       " 35.0: 23,\n",
       " 37.0: 24,\n",
       " 39.0: 25,\n",
       " 40.0: 26,\n",
       " 42.0: 27,\n",
       " 43.0: 28,\n",
       " 46.0: 29,\n",
       " 47.0: 30,\n",
       " 48.0: 31,\n",
       " 49.0: 32,\n",
       " 50.0: 33,\n",
       " 51.0: 34,\n",
       " 53.0: 35,\n",
       " 54.0: 36,\n",
       " 58.0: 37,\n",
       " 61.0: 38,\n",
       " 63.0: 39,\n",
       " 64.0: 40,\n",
       " 65.0: 41,\n",
       " 67.0: 42,\n",
       " 69.0: 43,\n",
       " 70.0: 44,\n",
       " 74.0: 45,\n",
       " 75.0: 46,\n",
       " 76.0: 47,\n",
       " 77.0: 48,\n",
       " 79.0: 49,\n",
       " 80.0: 50,\n",
       " 81.0: 51,\n",
       " 82.0: 52,\n",
       " 83.0: 53,\n",
       " 84.0: 54,\n",
       " 85.0: 55,\n",
       " 86.0: 56,\n",
       " 91.0: 57,\n",
       " 92.0: 58,\n",
       " 94.0: 59,\n",
       " 96.0: 60,\n",
       " 97.0: 61,\n",
       " 99.0: 62,\n",
       " 101.0: 63,\n",
       " 102.0: 64,\n",
       " 104.0: 65,\n",
       " 105.0: 66,\n",
       " 110.0: 67,\n",
       " 163.0: 68,\n",
       " 165.0: 69,\n",
       " 166.0: 70,\n",
       " 173.0: 71,\n",
       " 190.0: 72,\n",
       " 193.0: 73,\n",
       " 203.0: 74,\n",
       " 204.0: 75,\n",
       " 217.0: 76,\n",
       " 221.0: 77,\n",
       " 276.0: 78,\n",
       " 277.0: 79,\n",
       " 278.0: 80,\n",
       " 279.0: 81,\n",
       " 280.0: 82,\n",
       " 290.0: 83,\n",
       " 292.0: 84,\n",
       " 293.0: 85,\n",
       " 294.0: 86,\n",
       " 295.0: 87,\n",
       " 296.0: 88,\n",
       " 297.0: 89,\n",
       " 298.0: 90,\n",
       " 299.0: 91,\n",
       " 301.0: 92,\n",
       " 303.0: 93,\n",
       " 307.0: 94,\n",
       " 308.0: 95,\n",
       " 309.0: 96,\n",
       " 310.0: 97,\n",
       " 311.0: 98,\n",
       " 312.0: 99,\n",
       " 314.0: 100,\n",
       " 317.0: 101,\n",
       " 321.0: 102,\n",
       " 322.0: 103,\n",
       " 323.0: 104,\n",
       " 324.0: 105,\n",
       " 325.0: 106,\n",
       " 331.0: 107,\n",
       " 333.0: 108,\n",
       " 334.0: 109,\n",
       " 340.0: 110,\n",
       " 343.0: 111,\n",
       " 346.0: 112,\n",
       " 348.0: 113,\n",
       " 350.0: 114,\n",
       " 356.0: 115,\n",
       " 362.0: 116,\n",
       " 365.0: 117,\n",
       " 367.0: 118,\n",
       " 368.0: 119,\n",
       " 371.0: 120,\n",
       " 375.0: 121,\n",
       " 378.0: 122}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_to_idx_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_ids = data.user_id.unique()\n",
    "problem_to_idx_dict = generate_id_to_idx_dict(data, column='skill_id')\n",
    "\n",
    "tuples = []\n",
    "for id in user_ids:\n",
    "    df = sorted_data[sorted_data.user_id == id]\n",
    "    df = df[REQUIRE_COLS]\n",
    "    problems = [problem_to_idx_dict[pid] for pid in df.skill_id]\n",
    "    corrects = [corr for corr in df.correct]\n",
    "    num_problems = len(problems)\n",
    "#     print (num_problems)\n",
    "#     print (problems)\n",
    "#     print (corrects)\n",
    "#     print (\"============\")\n",
    "    result = (num_problems, problems, corrects)\n",
    "    tuples.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/b.csv', 'w') as f:\n",
    "    writer = csv.writer(f, \n",
    "                        delimiter=',', \n",
    "                        quotechar=\"'\", \n",
    "                        quoting=csv.QUOTE_MINIMAL,\n",
    "                        lineterminator='\\n')\n",
    "    for tup in tuples:\n",
    "        writer.writerow([tup[0]])\n",
    "        writer.writerow(tup[1])\n",
    "        writer.writerow(tup[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4217"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(problem_to_idx_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(tuples, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/skill_id_train.csv', 'w') as f:\n",
    "    writer = csv.writer(f, \n",
    "                        delimiter=',', \n",
    "                        quotechar=\"'\", \n",
    "                        quoting=csv.QUOTE_MINIMAL,\n",
    "                        lineterminator='\\n')\n",
    "    for tup in train:\n",
    "        writer.writerow([tup[0]])\n",
    "        writer.writerow(tup[1])\n",
    "        writer.writerow(tup[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/skill_id_test.csv', 'w') as f:\n",
    "    writer = csv.writer(f, \n",
    "                        delimiter=',', \n",
    "                        quotechar=\"'\", \n",
    "                        quoting=csv.QUOTE_MINIMAL,\n",
    "                        lineterminator='\\n')\n",
    "    for tup in test:\n",
    "        writer.writerow([tup[0]])\n",
    "        writer.writerow(tup[1])\n",
    "        writer.writerow(tup[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
